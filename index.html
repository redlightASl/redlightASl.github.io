<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://redlightasl.github.io">
  <title>红光今天吃什么</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="想搞FPGA的微电人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="红光今天吃什么">
<meta property="og:url" content="https://redlightasl.github.io/">
<meta property="og:site_name" content="红光今天吃什么">
<meta property="og:description" content="想搞FPGA的微电人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="RedlightASl">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="红光今天吃什么" type="application/atom+xml">
  
  
    <link rel="icon" href="/assets/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#f3c4ef,#a0cfe4);
    }
  </style>
  

  

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #9400d3"></div>
<!-- 左侧边栏（上半部分）不设置背景颜色 -->
<!-- <div class="overlay" > -->
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/assets/Patchouli.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a></li>
	        
			</ul>
		</nav>
		<!-- <nav> -->
			<!-- 总文章数 67 -->
		<!-- </nav>		 -->
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/redlightASl" title="github"><i class="icon-github"></i></a>
		        
					<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/redlightasl" title="zhihu"><i class="icon-zhihu"></i></a>
		        
					<a class="bilibili" target="_blank" href="https://space.bilibili.com/12073240" title="bilibili"><i class="icon-bilibili"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:dddbbbdd@foxmail.com" title="mail"><i class="icon-mail"></i></a>
		        
					<a class="twitter" target="_blank" href="https://twitter.com/Redligh34025775" title="twitter"><i class="icon-twitter"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #9400d3"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/Patchouli.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/redlightASl" title="github"><i class="icon-github"></i></a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/redlightasl" title="zhihu"><i class="icon-zhihu"></i></a>
			        
						<a class="bilibili" target="_blank" href="https://space.bilibili.com/12073240" title="bilibili"><i class="icon-bilibili"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:dddbbbdd@foxmail.com" title="mail"><i class="icon-mail"></i></a>
			        
						<a class="twitter" target="_blank" href="https://twitter.com/Redligh34025775" title="twitter"><i class="icon-twitter"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-我的新博客" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/13/%E6%88%91%E7%9A%84%E6%96%B0%E5%8D%9A%E5%AE%A2/">我的新博客</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2021/11/13/%E6%88%91%E7%9A%84%E6%96%B0%E5%8D%9A%E5%AE%A2/" class="archive-article-date">
  	<time datetime="2021-11-13T09:56:22.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-11-13</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="欢迎来看红光今天吃什么"><a href="#欢迎来看红光今天吃什么" class="headerlink" title="欢迎来看红光今天吃什么"></a>欢迎来看红光今天吃什么</h1><p>红光将在这里持续高强度整活（指写博文）</p>
<p>博文不定期更新，保障一个月两次的保底更新（大概）</p>
<p>欢迎dalao们指出博文的问题，同时欢迎大家提供整活思路</p>
<h3 id="活跃平台"><a href="#活跃平台" class="headerlink" title="活跃平台"></a>活跃平台</h3><ul>
<li>Github：有空就上去看两眼，一般会及时回复</li>
<li>知乎：平常刷一刷，不看私信，可以加一波好友但是不要指望用它联系我</li>
<li>b站：日常在线娱乐平台，不看私信</li>
<li>邮箱：秒回！</li>
<li>QQ：日常水群，一般会及时回复</li>
<li>微信公众号：日常不看，大概一两个月会发一次公众号推送，以最近沙雕图和技术博文（搬运）为主</li>
<li>神秘网站：一个月可能会上去看一看，正经人谁看推啊（</li>
</ul>
<p>推荐使用QQ<code>1429129330</code>或邮箱<code>dddbbbdd@foxmail.com</code>联系我</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
        <div class="article-pop-out tagcloud">
          <i class="icon-tuding"></i>
          <a class="article-tag-list-link color3">置顶</a>
        </div>
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">测试</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/11/13/%E6%88%91%E7%9A%84%E6%96%B0%E5%8D%9A%E5%AE%A2/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-硬件人的PyTorch【YOLO】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/">硬件人的PyTorch【YOLO】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-03-22T12:14:39.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基于PyTorch部署YOLO算法"><a href="#基于PyTorch部署YOLO算法" class="headerlink" title="基于PyTorch部署YOLO算法"></a>基于PyTorch部署YOLO算法</h1><p>本篇博文主要参考<a target="_blank" rel="noopener" href="https://github.com/bubbliiiing/yolo3-pytorch">Github开源代码</a>及对应教程总结</p>
<p>参考教程列在最后</p>
<h2 id="YOLO算法原理简介"><a href="#YOLO算法原理简介" class="headerlink" title="YOLO算法原理简介"></a>YOLO算法原理简介</h2><p>YOLO即<strong>You Only Look Once</strong>算法，到目前为止共有五个基本版本：从YOLO到YOLOv5，除此之外还有一些系列衍生版本，比较出名的就是旷视科技的YOLOx</p>
<p>其最大的特点是<strong>运行速度很快</strong>，可以用于实时系统——这一点和古老的RCNN算法相反，RCNN虽然很准但是太慢了</p>
<h3 id="YOLO基础原理"><a href="#YOLO基础原理" class="headerlink" title="YOLO基础原理"></a>YOLO基础原理</h3><p>对于目标检测任务，一直以来有两个流派：一个思路是将其分解为两个任务，先找到图片中某个存在对象的区域，然后再识别出该区域中具体是哪个对象，对于对象识别问题可以由很多经典的CNN算法完成，但对于寻找图像中目标所在区域却不好实现。一个最简单的想法就是遍历图片中所有可能的位置，逐一检测其中是否存在某个对象，挑选其中概率最大的作为输出——显然效率低得离谱</p>
<p>后来Fast RCNN/Faster RCNN出现了，先从图片中选出这些<strong>候选区</strong>（Region Proposals），再对其中的对象进行识别，最后还需要对候选区进行微调来让它们更接近真实的bounding box，这个过程称为<strong>边框回归</strong>。循规蹈矩的遍历-回归也正是它慢的原因。虽然Faster RCNN能将图片识别加快到5帧，但显然完全没有办法适应工业环境</p>
<blockquote>
<p>早期的Tow-Stage类型的算法（大都基于RNN实现）大都有这个痛点</p>
</blockquote>
<p>另一个思路的One-Stage类型算法则认为可以将目标检测看成一个任务，作为其中代表性算法的YOLO被提出解决了工业应用的问题</p>
<p>YOLO提出了新的解决方法：<strong>将目标检测看作独立的一个任务</strong>，也就是只要看一眼就能知道对象和它们的位置。不过YOLO还是借鉴了候选区的逻辑，将它内含于特性<strong>单元格</strong>（Grid Ceil）中，从而将一幅图片大致分成很多区域，挨个区域寻找。同时YOLO也使用了预定义的<strong>先验框</strong>（Prier Box）来近似边框回归的过程。</p>
<p>一幅图片被划分成很多<strong>单元格</strong>（Grid Ceil），<strong>每个单元格负责去检测那些中心点落在该格子内的目标</strong>，如下图，狗的中心点位于红点所在单元格，该单元格负责预测这个狗，每个单元格会预测周围的复数个边界框，并获取对应边界框的置信度（Confidence Score），置信度包含两个方面：<em>所预测边界框含有目标的可能性大小</em>$Pr(object)$和<em>对应边界框的准确度IOU</em>。</p>
<blockquote>
<p>YOLO的一个原则就是“<em>对自己负责</em>”：一个Object只由一个grid来进行预测，不要多个grid都抢着预测同一个Object。更具体地说就是在设置训练样本的时候，样本中每个Object归属到且仅归属到一个grid，即使有时Object跨越了几个grid，也仅指定其中一个。具体就是计算出该Object的边界框的中心位置，这个中心位置落在哪个grid，该grid对应的输出向量中该对象的类别概率就是被定为1（该gird负责预测该对象），所有其它grid对该Object的预测概率设为0（不负责预测该对象），这样既满足了<em>条件概率（下面会谈到）</em>，也能实现目标检测任务的精准划分</p>
</blockquote>
<p>边界框的准确度可以用预测框与<strong>实际框</strong>（Ground Truth）的<strong>IOU</strong>（Intersection Over Union，<strong>交并比</strong>）来表征</p>
<blockquote>
<p>当对应边界框是背景，不包含目标时，$Pr(object)=0$；当边界框包含目标时，$Pr(object)=1$，这是一个二值函数。说人话就是如果边界框里面有目标的中心点，则设置$Pr(object)=1$，否则设为0</p>
<p>IOU表征了预测的Bounding Box与真实框Ground Truth的接近程度，这个IOU是在训练阶段计算的，用来让模型收敛</p>
<p>IOU=交集部分面积/并集部分面积，2个框完全重合时，IOU=1，不相交时IOU=0</p>
</blockquote>
<p>综合上述因素，可知YOLO输出的总置信度本质上相当于一个条件概率$P(C_i|object)$，其中object表示该单元格内含有目标的可能性大小，$C_i$表示该单元格内物体是$C_i$这个种类的概率，最后可以得到$置信度Confidence=Pr(object)*IOU$</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220319231433136.png" alt="image-20220319231433136"></p>
<p>完成了单一划分单元格的预测还不够，因为实际物体有大有小，YOLOv1、v2的缺陷就在于难以预测小物体，于是从YOLOv3开始就引入了多重Scale的概念。它通过对图像下采样建立一个图形金字塔来实现针对大、中、小号物体的检测：比如一张416x416像素的图片，可以将其分成大单元格组成（每个格子是52x52像素，共有个8x8个框）、中单元格组成（每个单元格是26x26像素，共有16x16个框）、小单元格组成（每个单元格是13x13像素，共有32x32个框）的三种<strong>特征图</strong>（Feature Map），对每个特征图进行分析从而更完善地实现目标检测</p>
<p>对于多重Scale，目前主要有以下几种主流方法，如下图所示：</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/v2-2794a0cd1c59e7c4e9293ee757d91872_r.jpg" alt="preview"></p>
<p>(a) 这种方法最直观。首先对于一幅图像建立图像金字塔，不同级别的金字塔图像被输入到对应的网络当中，用于不同scale物体的检测。但这样做的结果就是每个级别的金字塔都需要进行一次处理，速度很慢。</p>
<p>(b) 检测只在最后一个特征图上进行，这个结构无法检测不同大小的物体。</p>
<p>(c) 对不同深度的特征图分别进行目标检测。SSD中采用的便是这样的结构。缺点在于每一个特征图获得的信息仅来源于之前的层，之后的层的特征信息无法获取并加以利用。</p>
<blockquote>
<p>SSD算法采用了这样一种思路：特征层（Feature Layer）的大小随层数不断增加而逐渐减小，并且每产生一个特征层，都会对这一层进行目标检测，然后所有的检测结果都会被Fast NMS合并筛选，最终生成最后的bbox。它的原本思路是在不同深度的特征图获得后，直接进行目标检测，这样小的物体会在相对较大的特征图中被检测出来，而大的物体会在相对较小的特征图中被检测出来。这样的结构有助于检测到不同大小的物体，但是会忽略下一层可能得到的增殖特征。在实际的特征图中，深度不同所对应的特征图包含信息不是绝对相同的。随着网络深度的加深，浅层的特征图中主要包含低级的信息（物体边缘，颜色，初级位置信息等），深层的特征图中包含高等信息（例如物体的语义信息：狗，猫，汽车等等）。因此在不同级别的特征图中进行检测，听起来好像可以对应不同的Scale，但是实际上精度并没有期待的那么高。</p>
</blockquote>
<p>(d) 与(c)很接近，但有一点不同的是<strong>当前层的特征图会对未来层的特征图进行上采样并加以利用</strong>。这是一个有跨越性的设计，因为有了这样一个结构，当前的特则会概念图就可以获得“未来”层的信息，从而让低阶特征与高阶特征有机融合，提升检测精度</p>
<p>YOLO先通过特征提取网络对输入图像提取特征，得到三种大小的<strong>特征图</strong>（Feature Map）：<strong>52x52</strong>、<strong>26x26</strong>、<strong>13x13</strong>，然后对应分出52x52、26x26、13x13个<strong>grid cell</strong>，如果某个目标的中心位于哪个grid cell里，就由对应的grid cell来预测目标的种类，YOLO要求每个grid cell都会预测<em>固定数量</em>的<strong>边界框</strong>（Bounding Box），只有和IOU最大的边界框才能用于预测对应目标</p>
<blockquote>
<p>YOLO就是用了(d)思路，YOLOv3将采样网络的最后三层输出分别使用上采样网络和Concat进行连接，进一步提取预测特征</p>
</blockquote>
<p><strong>YOLO的输出是不能直接使用的，需要先进行解码（Decode）才能在图像上绘制图框、标记种类和确信度</strong></p>
<h3 id="YOLO结构与输入输出"><a href="#YOLO结构与输入输出" class="headerlink" title="YOLO结构与输入输出"></a>YOLO结构与输入输出</h3><p>YOLO算法大致可以分成三个部分：</p>
<ul>
<li>Backbone：残差卷积，用于提取图像特征，作为YOLO主干网络，可以随意替换</li>
<li>Neck：上采样网络，用于将图像特征通过图像金字塔融合</li>
<li>Prediction：预测结果处理，进行特征图到Tensor的映射，同时负责同一对象多种类分辨</li>
</ul>
<p>要求输入为416x416像素的RGB图像，一般来说被保存为<code>Tensor[-1, 416, 416, 3]</code>。输出是一个<code>Tensor[-1, 7, 7, 30]</code>（v1）或<code>Tensor[-1, 56, 56, 255]</code>（v3）</p>
<p>每个版本的YOLO输入输出格式大都不一样，不过它们的映射关系是类似的：将输入的三通道图像（<code>Tensor[&lt;输入图像宽&gt;, &lt;输入图像高&gt;, 3]</code>）映射为对应scale的信息张量（<code>Tensor[&lt;输出scale&gt;, &lt;输出scale&gt;, P&lt;每个可能目标种类的概率&gt;+C&lt;每个边界框的置信度&gt;+S&lt;边界框的位置坐标&gt;]</code>）</p>
<p>输入很好理解，就是RGB图像</p>
<p>输出Scale表示的是当前特征图在x、y方向的单元格数</p>
<p>每个YOLO版本对应的可支持识别对象种类数决定了P：比如YOLOv1支持20种不同目标种类，那么P=20</p>
<blockquote>
<p>需要注意：这里的概率表示条件概率，其条件概率值都是对应网格位置存在任意一种对象条件下对应目标种类的概率</p>
<p>也就是说如果该网格存在一个对象，那么其条件：对应网格位置存在任意一种对象的概率为1，否则为0</p>
<p>在此基础上，对应目标种类$C_i$的概率才是其边界框置信度概率P</p>
</blockquote>
<p>最后的S是四个边界框位置参数：<strong>width、height、centre_x、centre_y</strong></p>
<p>为了从输出的复杂Tensor中提取出最有可能的那些对象和位置，YOLO采用<strong>NMS</strong>（Non-maximal suppression，<strong>非极大值抑制</strong>）算法。其核心思想是：<strong>选择得分最高的作为输出，与该输出重叠的去掉，不断重复这一过程直到所有备选处理完</strong>，主要解决的是一个目标被多次检测的问题</p>
<blockquote>
<p>在很多情况下，会被多次同一个边界框会被多次检测，但是我们希望最后仅仅输出其中一个置信度最高的预测框和对应的种类，使用NMS算法可以这样实现：首先从所有的检测框中找到置信度最大的那个框，然后挨个计算其与剩余框的IOU，如果其值大于一定阈值（重合度过高），那么就将该框剔除；然后对剩余的检测框重复上述过程，直到处理完所有的检测框</p>
</blockquote>
<p>针对YOLO的实际预测过程，这里我们不考虑批输入，认为只是预测一张输入图片，以YOLOv1为例。</p>
<p>最终的网络输出是7x7x30的Tensor，我们可以将其分割成三个部分：类别概率部分为<code>Tensor[7,7,20]</code>，置信度部分为<code>Tensor[7,7,2]</code>，而边界框部分为<code>Tensor[7,7,2,4]</code>（<em>需要先根据原始图片和先验框计算出其真实值</em>）。然后将前两项相乘得到真正的置信度，这样所有的准备数据已经得到了（每个边界框对于所有种类各自的真正置信度）</p>
<p>最自然的思路就是：首先对于每个预测框根据类别置信度选取置信度最大的那个类别作为其预测标签，预先设置一个置信度阈值，将置信度小于该阈值的框过滤掉，剩余的是置信度比较高的预测框，最后再对这些预测框使用NMS算法，留下来的就是检测结果</p>
<blockquote>
<p>NMS是对所有预测框一视同仁或者区分类别进行计算需要仔细考虑。一般来说大家都<strong>区分每个类别分别使用NMS</strong>，但是在某些情况下一视同仁的准确度更高</p>
</blockquote>
<p>YOLO算法的官方实现却采用了另外一个不同的处理思路：先使用NMS，然后再确定各个box的类别。</p>
<p>对于98个框，首先将小于置信度阈值的值归0，然后分类别地对置信度值采用NMS，这里NMS处理结果不是剔除，而是将其置信度值归为0。最后才是确定各个box的类别，当其置信度值不为0时才做出检测结果输出。</p>
<p>如下所述：</p>
<ol>
<li>设置一个Score的阈值，低于该阈值的候选对象排除掉（将对应Score设为0）</li>
<li>遍历每一个对象类别使用NMS</li>
<li>遍历该对象的98个Score</li>
<li>找到Score最大的那个对象及其bounding box，添加到输出列表</li>
<li>对每个Score不为0的候选对象，计算其与前一步输出对象的边界框的IOU</li>
<li>根据预先设置的IOU阈值，所有高于该阈值（重叠度较高）的候选对象排除掉（将Score设为0）</li>
<li>如果所有边界框要么在输出列表中，要么Score=0，则该对象类别的NMS完成，返回步骤2处理下一种对象 </li>
<li>获得输出列表即为预测的对象</li>
</ol>
<blockquote>
<p>根据原论文所述，NMS算法对YOLO的性能影响很大，为了尽可能提高速度，就采用了这种不是很直接的思路</p>
</blockquote>
<p><strong>不过两种策略结果是一样的</strong></p>
<h3 id="YOLO的训练特点"><a href="#YOLO的训练特点" class="headerlink" title="YOLO的训练特点"></a>YOLO的训练特点</h3><p>由于YOLO是呈现前后解耦的三个主干网络，所以训练时会优先对最前面的下采样网络（特征提取网络）进行预训练，在此基础上训练整体网络</p>
<blockquote>
<p>YOLO官方先使用了ImageNet数据集对前20层卷积网络进行预训练，然后再使用完整的网络</p>
</blockquote>
<p>YOLO的最后一层采用线性激活函数，其它层都是LeakyReLU。训练中还采用了drop out和数据增强（data augmentation）来防止过拟合</p>
<h3 id="YOLOv3算法结构"><a href="#YOLOv3算法结构" class="headerlink" title="YOLOv3算法结构"></a>YOLOv3算法结构</h3><p>YOLOv3算法结构图如下所示</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/v2-f2eb38d191395716299f0c8bf5807e94_720w.jpg" alt="img"></p>
<p>可以发现算法主要由三部分组成：</p>
<ul>
<li>Backbone：实际上是一个Darknet53残差神经网络，用于提取图片中的特征</li>
<li>Neck：进行上采样，将提取出的特征分成三个部分输出</li>
<li>Prediction：用于处理图像识别结果并以锚点方式输出</li>
</ul>
<p>将上面的结构图转换成下面的形式会更方便理解</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/v2-fb8b964727ccfea93345ba1361c4c8a3_r.jpg" alt="preview"></p>
<p>其中Backbone部分可以看成由一个CBL和5个ResNet构成</p>
<ul>
<li><p><strong>CBL</strong>：也常称为<strong>DBL</strong>，YOLOv3中的最小组件，包含了<code>Conv-BN-LeakyReLU</code>这样的结构，可以看成经过改进的卷积单元组合</p>
<blockquote>
<p>CBL就是取结构首字母<strong>C</strong>onv-<strong>B</strong>N-<strong>L</strong>eakyReLU组成的</p>
<p>DBL的意思就是“Darknet Basic Layer”</p>
<p>两种名称都可以称呼这个组织结构（把LeakyReLU换成普通ReLU也可以用这个名称描述）</p>
</blockquote>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220319215520661.png" alt="image-20220319215520661"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(inplanes, planes[<span class="number">0</span>], kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(planes[<span class="number">0</span>])</span><br><span class="line">self.relu1 = nn.LeakyReLU(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure></li>
<li><p><strong>ResNet Unit</strong>：残差单元，结构如下图所示</p>
<p>  <img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220319214641913.png" alt="image-20220319214641913"></p>
<p>  两层CBL加一条<strong>残差边</strong>就构成了残差单元，在后面会遇到<strong>ResNetx</strong>的写法，表示内部有x个残差组件外加一个CBL</p>
<p>  残差边指的是从输入直接连到输出并和两个CBL输出叠加的那一部分数据</p>
<p>  <img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220319215627613.png" alt="image-20220319215627613"></p>
<p>  ResNetx中的CBL起到了下采样的作用</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResUnit</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplanes, planes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResUnit, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(</span><br><span class="line">            inplanes, planes[<span class="number">0</span>], kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes[<span class="number">0</span>])</span><br><span class="line">        self.relu1 = nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(</span><br><span class="line">            planes[<span class="number">0</span>], planes[<span class="number">1</span>], kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes[<span class="number">1</span>])</span><br><span class="line">        self.relu2 = nn.LeakyReLU(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line">        <span class="comment"># CBL_1</span></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu1(out)</span><br><span class="line">        <span class="comment"># CBL_2</span></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu2(out)</span><br><span class="line">        <span class="comment"># ADD</span></span><br><span class="line">        out += residual</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></li>
</ul>
<p>接下来会遇到[1, 2, 8, 8, 4]这个数组，表示Backbone部分是由下面的结构串成的</p>
<p><code>CBL-ResNet1-ResNet2-ResNet8-ResNet8-ResNet4</code></p>
<p>在两个ResNet8和ResNet4的输出部分，会引出三个Feature Map</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220319215657548.png" alt="image-20220319215657548"></p>
<p>接下来三个Feature Map会被引入到Neck部分做进一步<strong>上采样</strong>（UpSampling）</p>
<p>首先进行分析的是最小的特征图13x13：它是由ResNet4输出的，会首先被送到一个上采样层</p>
<ul>
<li><p>UpSampling：连续的五层Conv，如下所示</p>
<p>  这个特征图会被五层Conv处理，从而得到第一个<strong>预测节点</strong>输出</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_last_layers</span>(<span class="params">filters_list, in_filters, out_filter</span>):</span></span><br><span class="line">    <span class="comment"># Generate Last Layer</span></span><br><span class="line">    m = nn.Sequential(</span><br><span class="line">        conv2d(in_filters, filters_list[<span class="number">0</span>], <span class="number">1</span>), <span class="comment"># get feature 1</span></span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>), <span class="comment"># get feature 2</span></span><br><span class="line">        conv2d(filters_list[<span class="number">1</span>], filters_list[<span class="number">0</span>], <span class="number">1</span>), <span class="comment"># get feature 3</span></span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>), <span class="comment"># get feature 4</span></span><br><span class="line">        conv2d(filters_list[<span class="number">1</span>], filters_list[<span class="number">0</span>], <span class="number">1</span>), <span class="comment"># get feature 5</span></span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>), <span class="comment"># get result 1</span></span><br><span class="line">        nn.Conv2d(filters_list[<span class="number">1</span>], out_filter, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">True</span>) <span class="comment"># get result 2</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line">...</span><br><span class="line">self.last_layer0 = make_last_layers([<span class="number">512</span>, <span class="number">1024</span>], out_filters[-<span class="number">1</span>], <span class="built_in">len</span>(anchors_mask[<span class="number">0</span>]) * (num_classes + <span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<p>  需要注意：这里与上面的图示存在差别，因为在YOLOv3的各版本实现中Prediction部分是不同的！</p>
</li>
<li><p>上采样金字塔：将第一层预测节点输出作为下一次输入的一部分，通过<strong>Concat</strong>和第二个ResNet8的输出连接，这个操作并不会将二者相加，而是会改变输出Tensor的维度</p>
<p>  接下来就是再次通过5层CBL运算得到第二个预测节点的输出</p>
<p>  重复这一步骤，将第二个预测节点输出和第一个ResNet8的输出相Concat，再通过5层CBL就得到了第三个预测节点</p>
</li>
</ul>
<p>最后，得到的三个预测节点被送到Prediction部分，每个预测节点都会通过两层<code>CBL-Conv</code>处理，分别得到三种不同大小的锚点</p>
<ul>
<li>13x13特征图：13x13x255</li>
<li>26x26特征图：26x26x255</li>
<li>52x52特征图：52x52x255</li>
</ul>
<p>最后一部分的PyTorch实现如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">	<span class="comment"># Get Features in Shape of:</span></span><br><span class="line">    <span class="comment"># 52,52,256 max</span></span><br><span class="line">    <span class="comment"># 26,26,512 mid</span></span><br><span class="line">	<span class="comment"># 13,13,1024 min</span></span><br><span class="line">    x2, x1, x0 = self.backbone(x)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Feature3 from out5</span></span><br><span class="line"><span class="string">    13,13,1024 -&gt; 13,13,512 -&gt; 13,13,1024 -&gt; 13,13,512 -&gt; 13,13,1024 -&gt; 13,13,512</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get Branch</span></span><br><span class="line">    out0_branch = self.last_layer0[:<span class="number">5</span>](x0)</span><br><span class="line">    out0        = self.last_layer0[<span class="number">5</span>:](out0_branch) <span class="comment"># out0 = (batch_size,255,13,13)</span></span><br><span class="line">    <span class="comment"># UpSample</span></span><br><span class="line">    <span class="comment"># 13,13,512 -&gt; 13,13,256 -&gt; 26,26,256</span></span><br><span class="line">    x1_in = self.last_layer1_conv(out0_branch)</span><br><span class="line">    x1_in = self.last_layer1_upsample(x1_in)</span><br><span class="line">    <span class="comment"># Concat</span></span><br><span class="line">    <span class="comment"># 26,26,256 + 26,26,512 -&gt; 26,26,768</span></span><br><span class="line">    x1_in = torch.cat([x1_in, x1], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Feature2 from out4</span></span><br><span class="line"><span class="string">    26,26,768 -&gt; 26,26,256 -&gt; 26,26,512 -&gt; 26,26,256 -&gt; 26,26,512 -&gt; 26,26,256</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get Branch</span></span><br><span class="line">    out1_branch = self.last_layer1[:<span class="number">5</span>](x1_in)</span><br><span class="line">    out1        = self.last_layer1[<span class="number">5</span>:](out1_branch) <span class="comment"># out1 = (batch_size,255,26,26)</span></span><br><span class="line">    <span class="comment"># UpSample</span></span><br><span class="line">    <span class="comment"># 26,26,256 -&gt; 26,26,128 -&gt; 52,52,128</span></span><br><span class="line">    x2_in = self.last_layer2_conv(out1_branch)</span><br><span class="line">    x2_in = self.last_layer2_upsample(x2_in)</span><br><span class="line">    <span class="comment"># Concat</span></span><br><span class="line">    <span class="comment"># 52,52,128 + 52,52,256 -&gt; 52,52,384</span></span><br><span class="line">    x2_in = torch.cat([x2_in, x2], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Feature1 from out3</span></span><br><span class="line"><span class="string">    52,52,384 -&gt; 52,52,128 -&gt; 52,52,256 -&gt; 52,52,128 -&gt; 52,52,256 -&gt; 52,52,128</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    out2 = self.last_layer2(x2_in)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output</span></span><br><span class="line">	<span class="keyword">return</span> out0, out1, out2</span><br></pre></td></tr></table></figure>

<p>整体来看，训练过程中对于每幅输入图像，YOLOv3会预测三个不同大小的3D tensor，对应三个不同的Scale。设计这三个Scale的目的就是为了能够检测出不同大小的物体。Tensor大小分别为52x52、26x26、13x13</p>
<p>以<code>Tensor[-1, 13, 13, 255]</code>为例，原始输入图像会被分成分割成13x13的<strong>单元格（grid cell）</strong>，每个单元格对应着3D tensor中的1x1x255这样一个长条形维度。255这个数字来源于<code>3*(80+4+1)</code>，其中<code>3</code>代表这个单元格包含3个边界框；<code>80</code>代表对应每个类别物体的置信度（Confidence）；<code>4</code>代表bounding  box的四个坐标；<code>1</code>代表物体置信度（Objectness Score）</p>
<blockquote>
<p>YOLOv3支持80个种类</p>
</blockquote>
<p>如果训练集中某一个实际框（Ground Truth）对应的目标中心恰好落在了输入图像的某一个单元格中，那么这个单元格就负责预测此物体的边界框（正如开头所说的YOLO算法思路一样），中心所在的这个单元格所对应的物体置信度就被赋予1，其余的单元格则为0（也就是$Pr(object)$）。此外每个单元格还被赋予3个不同大小的<strong>先验框</strong>（Prior Box）。在训练过程中，这个单元格会逐渐学会如何选择哪个大小的先验框，以及如何对这个先验框进行微调（即offset/coordinate）。YOLO遵循这样的规则：<strong>每个单元格只选取与实际框的IOU重合度最高的那个先验框</strong>。上面说有三个预设的不同大小的先验框——作者首先在训练前提前将COCO数据集中的所有bbox使用<code>K-means clustering</code>分成9个类别，每3个类别对应一个Scale，这样总共3个Scale。这样的先验信息可以有效帮助网络准确预测每个预测框的offset/coordinate，先验框也就成为了YOLO系列的一个传统。</p>
<p>YOLOv3的一个改进点就是<strong>将原来的单标签分类改进为多标签分类</strong>。将原来用于单标签多分类的softmax层换成用于多标签多分类的逻辑回归层。</p>
<p>原来分类网络中的softmax层都是假设一张图像或一个目标只属于一个类别，但在一些复杂场景下，一个object可能属于多个类</p>
<blockquote>
<p>比如预设的类别中存在apple和red apple这两类，那么就会多标签分类就会同时识别出这两个类</p>
</blockquote>
<p>逻辑回归层主要用到sigmoid函数，该函数可以将输入约束在0到1的范围内，因此当一张图像经过特征提取后的某一类输出经过sigmoid函数约束后如果大于0.5，就表示属于该类。</p>
<p><strong>但是加入Sigmoid的一个问题就在于计算量大大增加了！</strong></p>
<h3 id="Darknet的YOLO实现"><a href="#Darknet的YOLO实现" class="headerlink" title="Darknet的YOLO实现"></a>Darknet的YOLO实现</h3><p>darknet是官方的YOLO实现，使用基于C/C++的Darknet编写</p>
<blockquote>
<p>相比于TensorFlow来说，Darknet并没有那么强大，但是它完全由C实现且没有任何依赖，同时支持CPU和GPU运算</p>
</blockquote>
<p>源码通过<code>https://github.com/pjreddie/darknet</code>获取</p>
<p>git clone以后只需要使用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd darknet</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>就可以完成编译了</p>
<p>随后下载预训练的权重文件并将它放在darknet目录下就可以使用检测功能</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://pjreddie.com/media/files/yolov3.weights</span><br><span class="line">./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg</span><br></pre></td></tr></table></figure>

<p>darknet的yolo使用VOC格式数据集进行训练</p>
<h2 id="ultralytics的YOLOv5实现"><a href="#ultralytics的YOLOv5实现" class="headerlink" title="ultralytics的YOLOv5实现"></a>ultralytics的YOLOv5实现</h2><p>ultralytics的实现是很经典的工业场景实现，可以有效地部署在手机平台或边缘设备上。</p>
<p>yolov4是yolov3基础上的大规模改进；yolov5则没有对大框架进行改动，只是调整了网络结构来提高速度和准确度</p>
<h3 id="YOLOv4结构改进"><a href="#YOLOv4结构改进" class="headerlink" title="YOLOv4结构改进"></a>YOLOv4结构改进</h3><p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/v2-ccc16892e80035886e36c0100dbd444d_r.jpg" alt="preview"></p>
<p>如上图所示，Yolov4在Yolov3的基础上进行了很多的创新。</p>
<p>在结构方面，CBL被保留下来，同时加入了CSP结构、SPP结、PAN结构。虽然加入了一些新结构，但是总体上还是Backbone-Neck-Prediction三部分</p>
<p>里面的五个基本组件：</p>
<ul>
<li>CBM：Conv-BN-Mish组成的最小网络组件</li>
<li>CBL：Conv-BN-LeakyReLU组成的最小网络组件，v3里面CBL的保留</li>
<li>ResUnit：将v3里面的CBL改成CBM，结构不变</li>
<li>CSPx：借鉴CSPNet结构而来的特征提取组件，取代了v3中的ResNetx，依然是<code>[1, 2, 8, 8, 4]</code>构成残差特征提取网络</li>
<li>SPP：一套最大池化网网络的组合，用于对提取到的特征图进行<strong>多尺度融合</strong></li>
</ul>
<p>在算法思路部分，每个部分进行的改进如下：</p>
<ul>
<li>Input：采用<strong>Mosaic数据增强</strong>、<strong>cmBN</strong>、<strong>SAT自对抗训练</strong></li>
<li>Backbone：结合了<strong>CSPDarknet53</strong>、<strong>Mish</strong>激活函数、<strong>Dropblock</strong>，通过提升网络深度和复杂度获取更好的特征提取效果</li>
<li>Neck：加入了<strong>SPP模块</strong>和<strong>FPN+PAN结构</strong></li>
<li>Prediction：结构保留v3，改进训练时的损失函数<strong>CIOU_Loss</strong>和使用了<strong>DIOU_nmns</strong>算法</li>
</ul>
<p>接下来仔细说一下每个改进的作用及含义</p>
<h3 id="Mosaic数据增强"><a href="#Mosaic数据增强" class="headerlink" title="Mosaic数据增强"></a>Mosaic数据增强</h3><p>这是参考了<strong>CutMix数据增强</strong>提出的方法，使用4张图片随机缩放、裁剪、排布进行拼接，这样有助于丰富数据集、减少GPU使用</p>
<blockquote>
<p>训练时使用Mosaic数据增强，可以一次性计算4张图片的数据，使得Mini-batch大小并不需要很大，只要一个GPU就可以获得比较好的效果</p>
</blockquote>
<p>如果上一个iteration中，小物体产生的<strong>loss不足</strong>（比如小于某一个阈值），则下一个iteration就用<strong>拼接图</strong>；否则就用<strong>正常图片</strong>训练</p>
<h3 id="CSPDarknet53结构"><a href="#CSPDarknet53结构" class="headerlink" title="CSPDarknet53结构"></a>CSPDarknet53结构</h3><p>这是在Darknet53基础上借鉴CSPNet经验组成的特征提取网络，并且引入了Backbone部分特供的<strong>Mish激活函数</strong><br>$$<br>mish=x*tanh(ln(1+e^x))<br>$$<br>它和LeakyReLU的区别在于负半轴，LeakyReLU在负半周有一个固定的斜率$\lambda$，而mish则有一个非常近似于0的非线性部分</p>
<blockquote>
<p>这个非线性部分很好地增强了网络的性能，不过对于嵌入式设备来说太不友好了！tanh、ln和exp的组合就像1453年的奥斯曼帝国打君士坦丁堡一样狂暴鸿儒缺少大规模dsp甚至是fpu的嵌入式设备，嵌入式设备还是应该老老实实用LeakyReLU/普通ReLU</p>
</blockquote>
<p>CSP的总体结构和Darknet类似，只不过把CBL换成了<strong>CBM</strong>（<strong>C</strong>onv-<strong>B</strong>N-<strong>M</strong>ish）。每个CSP模块前面的卷积核的大小都是3x3，stride=2，起下采样作用</p>
<p>CSP模块先将基础层的特征映射划分为两部分，然后通过跨阶段层次结构将它们合并，在减少了计算量的同时可以保证准确率，如下图</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220321215349078.png" alt="image-20220321215349078"></p>
<p>注意右下角的CSPX，自第一个CBM起分成了两部分，一个部分经过残差网络提取深度特征，然后另一部分在经过简单处理后与深度特征融合</p>
<h3 id="Dropblock"><a href="#Dropblock" class="headerlink" title="Dropblock"></a>Dropblock</h3><p>YOLOv4的Dropblock和常见网络中的Dropout功能类似，也是缓解过拟合的一种正则化方式，通过<strong>随机删除减少神经元的数量，使网络变得更简单</strong>，这会随机的删减丢弃一些信息，但卷积层在丢失上层数据的情况下仍然可以从相邻的激活单元学习到相同的信息</p>
<p>这是YOLO系列中v4独有的功能</p>
<blockquote>
<p>看上去没什么用，实际上确实没什么用</p>
</blockquote>
<p>不过这个东西对于网络的性能没什么提升，还会让网络变慢，唯一的作用就是削弱训练过程中的过拟合</p>
<h3 id="SPP模块"><a href="#SPP模块" class="headerlink" title="SPP模块"></a>SPP模块</h3><p>SPP模块其实在Yolov3中已经存在了，在v4中得到了普遍应用。它使用多个池化层并行，参数为<code>[1*1（相当于直接输出）, 5*5, 9*9, 13*13]</code>，最后再Concat，能有效<strong>增加主干特征的接收范围，显著的分离了最重要的上下文特征</strong></p>
<p>这个模块在之后的YOLOv5中也有保留，对网络的提升效果很大</p>
<h3 id="FPN-PAN结构"><a href="#FPN-PAN结构" class="headerlink" title="FPN+PAN结构"></a>FPN+PAN结构</h3><p>YOLO最前面Backbone有着“下采样”形成图像金字塔的过程，最明显的部分就是<code>[12884]</code>里面8-8-4各自引出一个scale特征图，在v4里面把特征图的尺寸改变了，但思路没有变化，如下图左边的黄色箭头金字塔那样</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220321220544645.png" alt="image-20220321220544645"></p>
<p>8采样出76x76特征图，第二个8采样出38x38特征图，4采样出19x19特征图</p>
<p>上图右侧用绿色上采样箭头连起来的图像金字塔就是FPN结构——自顶向下将高层特征信息用上采样方式融合，正如上面对YOLO原理的分析，FPN这个重要结构会让当前层的特征图对未来层的特征图进行上采样并加以利用，可以说Neck部分最重要的算法就是它了！</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220321222917786.png" alt="image-20220321222917786"></p>
<p>YOLOv4中引入的PAN结构借鉴了PANet的思路（如上图），与FPN交叉使用，如下所示</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220321221032759.png" alt="image-20220321221032759"></p>
<p>不难发现，<strong>PAN结构在FPN的输出基础上又进行了一次下采样</strong>，对应下图右侧的三个Concat</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220321221126747.png" alt="image-20220321221126747"></p>
<p>这样结合的原因是：FPN层自顶向下传达<strong>强语义特征</strong>，而特征金字塔则自底向上传达<strong>强定位特征</strong>，从不同的主干层对不同的检测层进行参数聚合</p>
<p>整理一下采样的顺序：CSP4的19x19输出首先进入SPP，与来自第二个CSP8的输出Concat以后变为FPN金字塔的38x38特征图；19x19特征图在通过SPP后还会被缓存一下留着PAN金字塔使用。下一步就是第一个CSP8输出的76x76特征图与经过二次上采样的38x38特征图融合得到为PAN金字塔准备的76x76特征图；在这一过程中间，38x38特征图也被缓存下来。这样得到FPN金字塔的三层完整结构，首先进行76x76特征图与38x38特征图的混合下采样，最后是38x38与19x19的混合下采样，分别得到PAN金字塔的三层输出特征图。</p>
<p>最终Prediction部分获得三个特征图：</p>
<ul>
<li>76x76x255</li>
<li>38x38x255</li>
<li>19x19x255</li>
</ul>
<h3 id="IOU-Loss"><a href="#IOU-Loss" class="headerlink" title="IOU_Loss"></a>IOU_Loss</h3><p>目前有四种IOU损失函数的计算思路，他们的特征如下：</p>
<p><strong>IOU_Loss</strong>：主要考虑检测框和目标框重叠面积。</p>
<p><strong>GIOU_Loss</strong>：在IOU的基础上，解决边界框不重合时的问题。</p>
<p><strong>DIOU_Loss</strong>：在IOU和GIOU的基础上，考虑边界框中心点距离的信息。</p>
<p><strong>CIOU_Loss</strong>：在DIOU的基础上，考虑边界框宽高比的尺度信息。</p>
<p>在YOLO中训练和部署分类过程都需要使用IOU损失函数，YOLOv4在训练中使用CIOU，在最后分类时候的nms算法内嵌入了DIOU。CIOU_loss是在DIOU_loss的基础上添加影响因子，从而包含真实框的信息，在训练时用于回归。但在部署以后的矫正框过程中，不需要真实框信息，也就不用考虑影响因子，因此直接用DIOU_nms即可，这可以大大加快运算速度</p>
<h3 id="YOLOv5结构改进"><a href="#YOLOv5结构改进" class="headerlink" title="YOLOv5结构改进"></a>YOLOv5结构改进</h3><p>Yolov5官方代码中，给出的目标检测网络中一共有4个版本，分别是<strong>Yolov5s、Yolov5m、Yolov5l、Yolov5x</strong>四个模型。YOLOv5与v4地区别并不太大，但是相当有效地<strong>加快了推理速度</strong>，这让YOLOv5跑在更多嵌入式平台上。</p>
<blockquote>
<p>下面的几乎所有改进都是为了一个目的：加快运行速度、减小网络体积</p>
</blockquote>
<p>下面以最基础的<strong>YOLOv5s</strong>来介绍，这是yolov5中<strong>最小</strong>的网络。后面的3种都是在此基础上不断加深网络层数，不断加宽特征图宽度</p>
<p>YOLOv5在v4基础上做了如下改进：</p>
<ul>
<li>输入端：<strong>自适应锚框计算</strong>、<strong>自适应图片缩放</strong></li>
<li>Backbone：<strong>Focus结构</strong>、<strong>双CSP结构</strong></li>
<li>Neck：<strong>CSP2版本的FPN+PAN结构</strong></li>
<li>Prediction与输出端：没有其他重要改进</li>
</ul>
<p>下面来依次介绍</p>
<h3 id="自适应锚框计算"><a href="#自适应锚框计算" class="headerlink" title="自适应锚框计算"></a>自适应锚框计算</h3><p>YOLOv5的输入部分除了沿袭v4的Mosaic数据增强外，还引入了自适应锚框计算和图片缩放功能</p>
<p>在YOLO系列中，针对不同的数据集总会设置初始长宽的<strong>锚框</strong>（Anchor），网络训练中会在初始锚框基础上输出预测框并和真实框比对，再反向传播迭代网络参数，因此初始锚框总是YOLOv4以前网络很重要的一部分，YOLOv5也不例外。不过v5中将初始锚框计算功能嵌入到代码中，从而在每次训练时都能自适应计算不同训练集里面最佳的锚框值。</p>
<h3 id="自适应图片缩放"><a href="#自适应图片缩放" class="headerlink" title="自适应图片缩放"></a>自适应图片缩放</h3><p>常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，再送入检测网络中。YOLOv3使用416x416、v4使用608x608像素。为了让图片缩放长宽比保持恒定，就需要在图像边缘填充黑边，这让信息冗余从而影响推理速度。而YOLOv5代码中datasets.py的letterbox函数可以对原始图像<strong>自适应地添加最少黑边</strong>，这样就减少了计算量，让目标检测速度大大提高。</p>
<blockquote>
<p>理论上通过这种简单的改进，推理速度可以得到37%的提升</p>
<p>需要注意：<strong>只有在使用模型推理时才会采用缩减黑边的方式，从而提高目标检测和推理的速度</strong></p>
</blockquote>
<p>基本算法如下：</p>
<ol>
<li>分别按照长和宽计算缩放系数</li>
<li>选出更小的那个缩放系数</li>
<li>计算缩放后的尺寸并执行缩放</li>
<li>计算需要填充的黑边</li>
<li>将黑边区域使用<code>(114, 114, 114)</code>色彩填充（一种接近灰色的黑色）</li>
</ol>
<h3 id="Focus结构"><a href="#Focus结构" class="headerlink" title="Focus结构"></a>Focus结构</h3><p>这是YOLOv5中独有的结构，这个模块准确地说并不属于Backbone，而是它的一个前置操作，目的是在图片进入Backbone前，对图片进行切片操作</p>
<p>具体来说就是<strong>在一张图片中每隔一个像素拿到一个值</strong>（类似临近下采样），从而获得四种互补的图片，它们互补且没有信息丢失，从而让W、H信息集中到了通道空间，扩充输入通道为原来的4倍。最后将得到的新图片再次卷积就能获得<strong>没有信息丢失情况下的二倍下采样特征图</strong>了。</p>
<p>经过这样的改进后，<strong>参数量变少了，也就达到了提速的效果</strong>；同时下采样时没有信息的丢失，让后面的卷积效果增强</p>
<h3 id="双CSP结构"><a href="#双CSP结构" class="headerlink" title="双CSP结构"></a>双CSP结构</h3><p>Yolov4中只有主干网络使用了CSP结构；Yolov5中则设计了两种CSP：<strong>CSP1_X</strong>和<strong>CSP2_X</strong>结构，分别应用在Backbone和Neck网络中</p>
<p>CSP1_X的结构和原来的ResNetx结构类似；CSP2_X结构则是将CSP1_X里面的x个ResUnit换成了2x个CBL，如下图所示</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220322192651391.png" alt="image-20220322192651391"></p>
<p>CSP1计算量更大且有残差结构；CSP2稍小，更易于计算</p>
<p>CSP2应用到Neck部分以后，显著增强了网络特征融合的能力</p>
<p>在各个不同版本的YOLO中，最大的不同就是CSP的深度，如下图所示</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220322194013461.png" alt="image-20220322194013461"></p>
<p>从YOLOv5s到x，各层CSP的深度递增</p>
<h3 id="配环境"><a href="#配环境" class="headerlink" title="配环境"></a>配环境</h3><p>本篇重点在于把YOLO的原理，因此仅对环境配置简述</p>
<blockquote>
<p>需要声明：在算力受限的硬件设备上部署YOLOv5是很nt的，如果想要在MCU上部署算法请选择YOLOv3及以下，或者使用专用算法抑或是YOLOX-tiny这样的魔改版YOLO算法</p>
<p>下面的配置步骤适用于<strong>ultralytics</strong>的其他YOLO实现部署在PC端</p>
</blockquote>
<ol>
<li><p>安装anaconda和python环境</p>
</li>
<li><p>安装Cuda和Cudnn环境</p>
<p> 自行查阅其他教程，不再赘述。可以在Win或Linux下完成（视物理机情况而定）</p>
<p> 要求<strong>PyTorch&gt;=1.7</strong></p>
<p> <strong>PyTorch的依赖关系需要查看官网，和Cuda、Cudnn对应，千万不要装错</strong></p>
</li>
<li><p>下载源码文件并配置环境</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ultralytics/yolov5  # clone</span><br><span class="line">cd yolov5</span><br><span class="line">pip install -r requirements.txt  # install</span><br></pre></td></tr></table></figure>

<p> 其中可以考虑使用<code>pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code>来加速下载</p>
<p> 这一步一定要注意</p>
<p> <strong>Python&gt;=3.7.0</strong></p>
</li>
<li><p>下载权重文件</p>
<p> 从README.md文档里面最后<a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/releases">Pretrained Checkpoints</a>里面找到需要模型的权重文件，并将其下载到一个目录，在后面要用到</p>
</li>
<li><p>测试</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python detect.py --source 0 --weights=&quot;&lt;权重文件路径&gt;&quot; #使用摄像头检测</span><br><span class="line">python detect.py --source=“data/images/zidane.jpg” --weights=&quot;&lt;权重文件路径&gt;&quot; #使用默认图片测试</span><br></pre></td></tr></table></figure></li>
</ol>
<p>按照上面这几步就可以完成YOLO的测试了</p>
<p>如果需要在自己的项目里集成YOLO，可以参考README文件里面的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;ultralytics/yolov5&#x27;</span>, <span class="string">&#x27;yolov5s&#x27;</span>)  <span class="comment"># or yolov5m, yolov5l, yolov5x, custom</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Images</span></span><br><span class="line">img = <span class="string">&#x27;https://ultralytics.com/images/zidane.jpg&#x27;</span>  <span class="comment"># or file, Path, PIL, OpenCV, numpy, list</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">results = model(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Results</span></span><br><span class="line">results.<span class="built_in">print</span>()  <span class="comment"># or .show(), .save(), .crop(), .pandas(), etc.</span></span><br></pre></td></tr></table></figure>

<h3 id="训练自己的模型"><a href="#训练自己的模型" class="headerlink" title="训练自己的模型"></a>训练自己的模型</h3><p><strong>YOLOv5使用YOLO格式的数据集，标注的时候需要注意</strong></p>
<p>有两种保存数据集的方法</p>
<p>第一种是直接按照官方格式要求制作</p>
<p>需要四个基本目录：</p>
<ul>
<li>train_img：训练集图片目录</li>
<li>train_ann：训练集标注目录</li>
<li>val_img：测试集图片目录</li>
<li>val_ann：测试集标注目录</li>
</ul>
<p>图片目录放在一个images目录下；标注目录放在一个labels目录下；这两个目录还要同时放进一个总的根目录下</p>
<p>整体结构如下所示（下面的命名和上面所示不相同，实际上目录命名是比较随意的）</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/image-20220322200242502.png" alt="image-20220322200242502"></p>
<p>然后需要制作对应的dataset.yaml</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">train:</span> <span class="string">&lt;训练集图片的路径&gt;</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">&lt;测试集图片的路径&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">nc:</span> <span class="string">&lt;种类数&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;&lt;种类的名字1&gt;&#x27;</span>, <span class="string">&#x27;&lt;种类的名字2&gt;&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>一个根目录和对应的yaml文件要一起放在yolov5/data目录下以便使用（也可以放在其他位置，只要训练的时候用参数指定出来就行）</p>
<p>这样数据集就制作完毕了，可以用下面的命令开始训练</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --img 640 --data data/&lt;数据集的yaml文件&gt; --cfg models/&lt;模型的yaml文件&gt; --weights weights/&lt;模型的对应与训练权重文件&gt; --batch-size &lt;每批训练的数量&gt; --epochs &lt;迭代次数，一般50或以下即可&gt;</span><br></pre></td></tr></table></figure>

<p>训练完成后就可以按照上面的步骤进行测试了</p>
<h1 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程"></a>参考教程</h1><p><a target="_blank" rel="noopener" href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40332004">https://zhuanlan.zhihu.com/p/40332004</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46691043">https://zhuanlan.zhihu.com/p/46691043</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_29462849/article/details/81100165">https://blog.csdn.net/qq_29462849/article/details/81100165</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ywheunji/p/10809695.html">https://www.cnblogs.com/ywheunji/p/10809695.html</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xiaohu2022/article/details/79211732">https://blog.csdn.net/xiaohu2022/article/details/79211732</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/143747206">https://zhuanlan.zhihu.com/p/143747206</a></p>
<h3 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.02767.pdf">https://arxiv.org/pdf/1804.02767.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.10934.pdf">https://arxiv.org/pdf/2004.10934.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.01534">https://arxiv.org/abs/1803.01534</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习与机器视觉</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90YOLO%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-硬件人的PyTorch【模型训练】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91/">硬件人的PyTorch【模型训练】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-03-22T12:14:31.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>本系列博文主要根据开源的<a target="_blank" rel="noopener" href="https://github.com/datawhalechina/thorough-pytorch">thorough-pytorch</a>项目编写，感谢datawhalechina团队的dalao们分享学习经验</strong></p>
<h1 id="PyTorch训练模型"><a href="#PyTorch训练模型" class="headerlink" title="PyTorch训练模型"></a>PyTorch训练模型</h1><p>一个神经网络的典型训练过程如下：</p>
<ol>
<li>定义包含一些可学习参数（或者叫权重）的<strong>神经网络</strong></li>
<li>在输入<strong>数据集</strong>上迭代</li>
<li>通过网络<strong>处理</strong>输入</li>
<li>计算<strong>损失函数</strong><code>loss</code>（输出和正确答案的距离）</li>
<li>将梯度<strong>反向传播</strong>给网络的参数</li>
<li><strong>更新权重</strong>（一般使用简单的规则，如<code>weight = weight - learning_rate * gradient</code>）</li>
</ol>
<p>下面来分别介绍其中的关键流程在PyTorch上的实现</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>损失函数可以被理解成模型训练结果的负反馈，即数据输入到模型当中产生的结果与真实标签的评价指标，模型可以按照损失函数的目标来做出改进</p>
<p>通过<code>torch.nn</code>可以调用PyTorch中内置的损失函数，也可以自行搭建模型的损失函数</p>
<h3 id="二分类交叉熵损失函数"><a href="#二分类交叉熵损失函数" class="headerlink" title="二分类交叉熵损失函数"></a>二分类交叉熵损失函数</h3><p>使用下面的函数计算二分类任务时的<strong>交叉熵（Cross Entropy）</strong></p>
<p>在二分类中，label是0或1中的一个，因此对于进入交叉熵函数的输入为概率分布的形式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCELoss(</span><br><span class="line">    weight=<span class="literal">None</span>, <span class="comment">#每个类别的loss设置权值</span></span><br><span class="line">    size_average=<span class="literal">None</span>, <span class="comment">#为True时，返回的loss为平均值；为False时，返回的各样本的loss之和</span></span><br><span class="line">    reduce=<span class="literal">None</span>, <span class="comment">#为True时，loss的返回是标量</span></span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>一般来说，input为sigmoid激活层的输出，或者softmax的输出</p>
<p>计算公式如下：<br>$$<br>\ell(x, y)=\left{\begin{array}{ll}<br>\operatorname{mean}(L), &amp; \text { if reduction }=\text { ‘mean’ } \<br>\operatorname{sum}(L), &amp; \text { if reduction }=\text { ‘sum’ }<br>\end{array}\right.<br>$$</p>
<h3 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h3><p>上面二分类交叉熵损失函数的推广</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(</span><br><span class="line">    weight=<span class="literal">None</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    ignore_index=-<span class="number">100</span>, <span class="comment">#忽略某个类的损失函数</span></span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>计算公式如下：<br>$$<br>\operatorname{loss}(x, \text { class })=-\log \left(\frac{\exp (x[\text { class }])}{\sum_{j} \exp (x[j])}\right)=-x[\text { class }]+\log \left(\sum_{j} \exp (x[j])\right)<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出</span></span><br><span class="line"><span class="string">tensor(2.0115, grad_fn=&lt;NllLossBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="L1损失函数"><a href="#L1损失函数" class="headerlink" title="L1损失函数"></a>L1损失函数</h3><p>用这个函数计算得到结果与真实标签之间差值的绝对值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.L1Loss(</span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span> <span class="comment">#计算模式，默认求平均</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>其中reduction可以选择三种模式：</p>
<ul>
<li>none：逐个元素计算</li>
<li>sum：所有元素求和</li>
<li>mean：加权平均</li>
</ul>
<p>计算公式如下：<br>$$<br>L_{n} = | x_{n}-y_{n}|g)<br>$$</p>
<h3 id="MSE损失函数"><a href="#MSE损失函数" class="headerlink" title="MSE损失函数"></a>MSE损失函数</h3><p>使用下面的函数计算得到结果与真实标签之间差值的平方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(</span><br><span class="line">    size_average=<span class="literal">None</span>,</span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span> <span class="comment">#和上面的L1Loss一样</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>计算公式如下：</p>
<p>$$<br>l_{n}=\left(x_{n}-y_{n}\right)^{2}<br>$$</p>
<h3 id="平滑L1损失函数"><a href="#平滑L1损失函数" class="headerlink" title="平滑L1损失函数"></a>平滑L1损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SmoothL1Loss(</span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span>, </span><br><span class="line">    beta=<span class="number">1.0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>是L1的平滑输出，能够减轻离群点带来的影响</p>
<p>计算公式如下：<br>$$<br>\operatorname{loss}(x, y)=\frac{1}{n} \sum_{i=1}^{n} z_{i}<br>$$<br>其中，<br>$$<br>z_{i}=\left{\begin{array}{ll}<br>0.5\left(x_{i}-y_{i}\right)^{2}, &amp; \text { if }\left|x_{i}-y_{i}\right|&lt;1 \<br>\left|x_{i}-y_{i}\right|-0.5, &amp; \text { otherwise }<br>\end{array}\right.<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.SmoothL1Loss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SmoothL1Loss损失函数的计算结果为&#x27;</span>,output)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出</span></span><br><span class="line"><span class="string">SmoothL1Loss损失函数的计算结果为 tensor(0.7808, grad_fn=&lt;SmoothL1LossBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>通过可视化两种损失函数曲线来对比平滑L1和L1两种损失函数的区别</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.linspace(-<span class="number">10</span>, <span class="number">10</span>, steps=<span class="number">5000</span>)</span><br><span class="line">target = torch.zeros_like(inputs)</span><br><span class="line"></span><br><span class="line">loss_f_smooth = nn.SmoothL1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_smooth = loss_f_smooth(inputs, target)</span><br><span class="line">loss_f_l1 = nn.L1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_l1 = loss_f_l1(inputs,target)</span><br><span class="line"></span><br><span class="line">plt.plot(inputs.numpy(), loss_smooth.numpy(), label=<span class="string">&#x27;Smooth L1 Loss&#x27;</span>)</span><br><span class="line">plt.plot(inputs.numpy(), loss_l1, label=<span class="string">&#x27;L1 loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x_i - y_i&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss value&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91/3.5.2.png" alt="png"></p>
<p>可以看得出来，对于smoothL1来说，在0这个尖端处，过度更为平滑。</p>
<h3 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h3><p>计算公式：</p>
<p>$$<br>\operatorname{loss}(x, y)=\left{\begin{array}{ll}<br>1-\cos \left(x_{1}, x_{2}\right), &amp; \text { if } y=1 \<br>\max \left{0, \cos \left(x_{1}, x_{2}\right)-\text { margin }\right}, &amp; \text { if } y=-1<br>\end{array}\right.<br>$$<br>其中,<br>$$<br>\cos (\theta)=\frac{A \cdot B}{|A||B|}=\frac{\sum_{i=1}^{n} A_{i} \times B_{i}}{\sqrt{\sum_{i=1}^{n}\left(A_{i}\right)^{2}} \times \sqrt{\sum_{i=1}^{n}\left(B_{i}\right)^{2}}}<br>$$</p>
<p>这个损失函数应该是最广为人知道的，即<strong>对于两个向量做余弦相似度</strong>，如果两个向量的距离近，则损失函数值小，反之亦然。</p>
<p>这个函数可以有效确定向量之间推广的欧式距离</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CosineEmbeddingLoss(</span><br><span class="line">    margin=<span class="number">0.0</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="其他损失函数"><a href="#其他损失函数" class="headerlink" title="其他损失函数"></a>其他损失函数</h3><p>PyTorch内部支持了大量损失函数，可以查阅官方文档或本教程的原版repo了解详细内容，这里仅列举如下</p>
<ul>
<li><p>目标泊松分布的负对数似然损失</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.PoissonNLLLoss(</span><br><span class="line">    log_input=<span class="literal">True</span>, </span><br><span class="line">    full=<span class="literal">False</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    eps=<span class="number">1e-08</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>KL散度（相对熵）</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.KLDivLoss(</span><br><span class="line">    size_average=<span class="literal">None</span>,</span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span>, </span><br><span class="line">    log_target=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>MarginRankingLoss</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MarginRankingLoss(</span><br><span class="line">    margin=<span class="number">0.0</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>,</span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>二分类损失函数</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SoftMarginLoss(</span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>多标签边界损失函数</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiLabelMarginLoss(</span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>多分类的折页损失</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiMarginLoss(</span><br><span class="line">    p=<span class="number">1</span>, </span><br><span class="line">    margin=<span class="number">1.0</span>, </span><br><span class="line">    weight=<span class="literal">None</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>三元组损失</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.TripletMarginLoss(</span><br><span class="line">    margin=<span class="number">1.0</span>,</span><br><span class="line">    p=<span class="number">2.0</span>, </span><br><span class="line">    eps=<span class="number">1e-06</span>, </span><br><span class="line">    swap=<span class="literal">False</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>HingEmbeddingLoss</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.HingeEmbeddingLoss(</span><br><span class="line">    margin=<span class="number">1.0</span>, </span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>CTC损失函数</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CTCLoss(</span><br><span class="line">    blank=<span class="number">0</span>, </span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span>, </span><br><span class="line">    zero_infinity=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="PyTorch的优化器"><a href="#PyTorch的优化器" class="headerlink" title="PyTorch的优化器"></a>PyTorch的优化器</h2><p>深度学习的目标是通过不断改变网络参数，使得参数能够对输入做各种非线性变换拟合输出，从本质上讲就是一个复杂函数去寻找最优解</p>
<p>有以下两种方法计算深度神经网络的系数：</p>
<ol>
<li>暴力穷举一遍参数，这种方法的实施可能性为0</li>
<li>BP+优化器逼近求解。</li>
</ol>
<p>优化器<strong>根据网络反向传播的梯度信息来更新网络的参数</strong>，从而降低损失函数计算值，这样就使得模型输出更加接近真实标签</p>
<p>PyTorch提供<code>torch.optim</code>优化器框架，包含了一下几种优化器</p>
<ul>
<li>torch.optim.ASGD</li>
<li>torch.optim.Adadelta</li>
<li>torch.optim.Adagrad</li>
<li>torch.optim.Adam</li>
<li>torch.optim.AdamW</li>
<li>torch.optim.Adamax</li>
<li>torch.optim.LBFGS</li>
<li>torch.optim.RMSprop</li>
<li>torch.optim.Rprop</li>
<li>torch.optim.SGD</li>
<li>torch.optim.SparseAdam</li>
</ul>
<p>以上这些优化算法均继承于<code>Optimizer</code>类，基类定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, params, defaults</span>):</span>        </span><br><span class="line">        self.defaults = defaults <span class="comment">#优化器的超参数，以字典形式保存</span></span><br><span class="line">        self.state = defaultdict(<span class="built_in">dict</span>) <span class="comment">#参数的缓存</span></span><br><span class="line">        self.param_groups = [] <span class="comment">#管理的参数组，以列表形式保存，其中每个元素都是字典</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">zero_grad</span>(<span class="params">self, set_to_none: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        清空所管理参数的梯度</span></span><br><span class="line"><span class="string">        Pytorch张量的梯度不自动清零，所以每次反向传播后都需要清空梯度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    	<span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        	<span class="keyword">for</span> p <span class="keyword">in</span> group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">            	<span class="keyword">if</span> p.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment">#梯度不为空</span></span><br><span class="line">                	<span class="keyword">if</span> set_to_none: </span><br><span class="line">                    	p.grad = <span class="literal">None</span></span><br><span class="line">                	<span class="keyword">else</span>:</span><br><span class="line">                    	<span class="keyword">if</span> p.grad.grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        	p.grad.detach_()</span><br><span class="line">                    	<span class="keyword">else</span>:</span><br><span class="line">                        	p.grad.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">                    	p.grad.zero_()<span class="comment"># 梯度设置为0</span></span><br><span class="line">                        </span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, closure</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        执行一步梯度更新，同时更新参数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    	<span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">add_param_group</span>(<span class="params">self, param_group</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加参数组&quot;&quot;&quot;</span></span><br><span class="line">    	<span class="keyword">assert</span> <span class="built_in">isinstance</span>(param_group, <span class="built_in">dict</span>), <span class="string">&quot;param group must be a dict&quot;</span> <span class="comment">#检查类型是否为tensor</span></span><br><span class="line">		params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(params, torch.Tensor):</span><br><span class="line">        	param_group[<span class="string">&#x27;params&#x27;</span>] = [params]</span><br><span class="line">    	<span class="keyword">elif</span> <span class="built_in">isinstance</span>(params, <span class="built_in">set</span>):</span><br><span class="line">        	<span class="keyword">raise</span> TypeError(</span><br><span class="line">                <span class="string">&#x27;optimizer parameters need to be organized in ordered collections, but &#x27;</span></span><br><span class="line">				<span class="string">&#x27;the ordering of tensors in sets will change between runs. Please use a list instead.&#x27;</span></span><br><span class="line">            )</span><br><span class="line">   		<span class="keyword">else</span>:</span><br><span class="line">        	param_group[<span class="string">&#x27;params&#x27;</span>] = <span class="built_in">list</span>(params)</span><br><span class="line">    	<span class="keyword">for</span> param <span class="keyword">in</span> param_group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">        	<span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(param, torch.Tensor):</span><br><span class="line">            	<span class="keyword">raise</span> TypeError(</span><br><span class="line">                    <span class="string">&quot;optimizer can only optimize Tensors, &quot;</span></span><br><span class="line">					<span class="string">&quot;but one of the params is &quot;</span> + torch.typename(param)</span><br><span class="line">                )</span><br><span class="line">        	<span class="keyword">if</span> <span class="keyword">not</span> param.is_leaf:</span><br><span class="line">            	<span class="keyword">raise</span> ValueError(<span class="string">&quot;can&#x27;t optimize a non-leaf Tensor&quot;</span>)</span><br><span class="line"></span><br><span class="line">    	<span class="keyword">for</span> name, default <span class="keyword">in</span> self.defaults.items():</span><br><span class="line">        	<span class="keyword">if</span> default <span class="keyword">is</span> required <span class="keyword">and</span> name <span class="keyword">not</span> <span class="keyword">in</span> param_group:</span><br><span class="line">            	<span class="keyword">raise</span> ValueError(</span><br><span class="line">                    <span class="string">&quot;parameter group didn&#x27;t specify a value of required optimization parameter &quot;</span> +</span><br><span class="line">                    name</span><br><span class="line">                )</span><br><span class="line">        	<span class="keyword">else</span>:</span><br><span class="line">            	param_group.setdefault(name, default)</span><br><span class="line"></span><br><span class="line">    	params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">    	<span class="keyword">if</span> <span class="built_in">len</span>(params) != <span class="built_in">len</span>(<span class="built_in">set</span>(params)):</span><br><span class="line">        	warnings.warn(</span><br><span class="line">                <span class="string">&quot;optimizer contains a parameter group with duplicate parameters; &quot;</span></span><br><span class="line">				<span class="string">&quot;in future, this will cause an error; &quot;</span></span><br><span class="line">				<span class="string">&quot;see github.com/pytorch/pytorch/issues/40967 for more information&quot;</span>, </span><br><span class="line">                stacklevel=<span class="number">3</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">		param_set = <span class="built_in">set</span>()</span><br><span class="line">    	<span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        	param_set.update(<span class="built_in">set</span>(group[<span class="string">&#x27;params&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    	<span class="keyword">if</span> <span class="keyword">not</span> param_set.isdisjoint(<span class="built_in">set</span>(param_group[<span class="string">&#x27;params&#x27;</span>])):</span><br><span class="line">        	<span class="keyword">raise</span> ValueError(<span class="string">&quot;some parameters appear in more than one parameter group&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.param_groups.append(param_group) <span class="comment">#添加参数</span></span><br><span class="line">        </span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载状态参数字典，可以用来进行模型的断点续训练，继续上次的参数进行训练&quot;&quot;&quot;</span></span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取优化器当前状态信息字典&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>在使用过程中还需要注意：每个优化器都是一个类，要先进行实例化</p>
<h3 id="训练和评估"><a href="#训练和评估" class="headerlink" title="训练和评估"></a>训练和评估</h3><p>在完成上一篇博文的设置和本篇博文上述部分的了解后就可以正式加载数据训练模型了</p>
<p><strong>训练</strong>状态下模型的参数应该支持反向传播的修改；如果是验证或<strong>测试</strong>状态，则不应该修改模型参数。在PyTorch中模型的状态设置非常简便，如下的两个操作二选一即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.train() <span class="comment">#训练状态</span></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment">#测试状态</span></span><br></pre></td></tr></table></figure>

<p>训练时不需要再使用PyTorch内置的迭代器处理数据集，只要使用for循环读取DataLoader中的全部数据即可，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br></pre></td></tr></table></figure>

<p>注意要根据模型特征定义损失函数，这里使用预先定义的criterion</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = criterion(output, label)</span><br></pre></td></tr></table></figure>

<p>需要注意：<strong>开始新一批次训练时，应当先将优化器的梯度置零</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer.zero_grad()</span><br></pre></td></tr></table></figure>

<p>随后就要将数据放到CPU/GPU上进行后续计算，这里以使用Cuda的GPU加速为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data, label = data.cuda(), label.cuda()</span><br><span class="line">output = model(data)</span><br></pre></td></tr></table></figure>

<p>将损失函数loss反向传播回网络，同时使用优化器更新模型参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>

<p>这样一次训练就完成了</p>
<p>测试的流程基本与训练过程一致，不同点在于：</p>
<ul>
<li>需要<strong>预先设置torch.no_grad</strong>，以及<strong>将model调至eval模式</strong></li>
<li><strong>不需要</strong>将优化器的<strong>梯度置零</strong></li>
<li><strong>不需要</strong>将损失函数loss<strong>反向传播</strong></li>
<li><strong>不需要更新优化器</strong></li>
</ul>
<p>一个完整的训练过程如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        data, label = data.cuda(), label.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(label, output)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    train_loss = train_loss/<span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对应的，一个完整的验证过程如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val</span>(<span class="params">epoch</span>):</span>       </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> val_loader:</span><br><span class="line">            data, label = data.cuda(), label.cuda()</span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>)</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">            running_accu += torch.<span class="built_in">sum</span>(preds == label.data)</span><br><span class="line">            </span><br><span class="line">    val_loss = val_loss/<span class="built_in">len</span>(val_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss))</span><br></pre></td></tr></table></figure>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>下面以LeNet手写数字识别的PyTorch实现为例将这两篇的内容综述一遍</p>
<p><img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91/3.4.1.png" alt="3.4.1"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	LeNet实现</span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="comment">#卷积层C1到S2</span></span><br><span class="line">                                   nn.ReLU(), <span class="comment">#激活层</span></span><br><span class="line">                                   nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#池化层</span></span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Sequential(nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>), <span class="comment">#卷积层C3到S4</span></span><br><span class="line">                                   nn.ReLU(), <span class="comment">#激活层</span></span><br><span class="line">                                   nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#池化层</span></span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Sequential(nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), <span class="comment">#全连接层S4到C5（同时也是卷积层）</span></span><br><span class="line">                                 nn.BatchNorm1d(<span class="number">120</span>), <span class="comment">#批标准化层</span></span><br><span class="line">                                 nn.ReLU()) <span class="comment">#激活层</span></span><br><span class="line"></span><br><span class="line">        self.fc2 = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>), <span class="comment">#全连接层C5到F6</span></span><br><span class="line">            nn.BatchNorm1d(<span class="number">84</span>), <span class="comment">#批标准化层</span></span><br><span class="line">            nn.ReLU(), 激活层</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)) <span class="comment">#全连接层F6到OUTPUT</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播函数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = self.conv1(x) <span class="comment">#卷积操作1</span></span><br><span class="line">        x = self.conv2(x) <span class="comment">#卷积操作2</span></span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>], -<span class="number">1</span>) <span class="comment">#对参数实现扁平化（便于后面全连接层输入）</span></span><br><span class="line">        x = self.fc1(x) <span class="comment">#通过全连接层进行最后的分类</span></span><br><span class="line">        x = self.fc2(x) <span class="comment">#全连接层输出</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">预览数据集</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 下载训练集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;./num/&#x27;</span>, <span class="comment">#用于指定数据集在下载之后的存放路径</span></span><br><span class="line">                               train=<span class="literal">True</span>, <span class="comment">#指定在数据集下载完成后需要载入的那部分数据:True 载入训练集；False 载入测试集</span></span><br><span class="line">                               transform=transforms.ToTensor(), <span class="comment">#用于指定导入数据集需要对数据进行哪种变化操作</span></span><br><span class="line">                               download=<span class="literal">True</span>) <span class="comment">#需要程序自动下载</span></span><br><span class="line"><span class="comment"># 下载测试集</span></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;./num/&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              transform=transforms.ToTensor(), </span><br><span class="line">                              download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span> <span class="comment">#建立一个数据迭代器</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#装载训练集</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, <span class="comment">#用于指定我们载入的数据集名称</span></span><br><span class="line">                                           batch_size=batch_size, <span class="comment">#设置每个包中的图片数据个数</span></span><br><span class="line">                                           shuffle=<span class="literal">True</span>) <span class="comment">#在装载的过程会将数据随机打乱顺序并进打包</span></span><br><span class="line"><span class="comment">#装载测试集</span></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class="line">                                          batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#实现单张图片可视化</span></span><br><span class="line">images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line">img = torchvision.utils.make_grid(images)</span><br><span class="line"></span><br><span class="line">img = img.numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">std = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">mean = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">img = img * std + mean</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;train_loader&#x27;</span>, img) <span class="comment">#查看图片</span></span><br><span class="line"></span><br><span class="line">key_pressed = cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">训练网络</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">LR = <span class="number">0.001</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>) <span class="comment">#使用GPU的Cuda核心进行运算</span></span><br><span class="line">net = LeNet().to(device) <span class="comment">#将数据传输到GPU</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment">#损失函数使用交叉熵</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=LR) <span class="comment">#优化函数使用 Adam 自适应优化算法</span></span><br><span class="line"></span><br><span class="line">epoch = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        sum_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">            inputs, labels = data</span><br><span class="line">            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad() <span class="comment">#将梯度归零</span></span><br><span class="line"></span><br><span class="line">            outputs = net(inputs) <span class="comment">#将数据传入网络进行前向运算</span></span><br><span class="line"></span><br><span class="line">            loss = criterion(outputs, labels) <span class="comment">#得到损失函数</span></span><br><span class="line"></span><br><span class="line">            loss.backward() <span class="comment">#反向传播</span></span><br><span class="line"></span><br><span class="line">            optimizer.step() <span class="comment">#通过梯度做一步参数更新</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># print(loss)</span></span><br><span class="line">            sum_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d,%d] loss:%.03f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, i + <span class="number">1</span>, sum_loss / <span class="number">100</span>))</span><br><span class="line">                sum_loss = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    测试网络</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    net.<span class="built_in">eval</span>() <span class="comment">#将模型变换为测试模式</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_test <span class="keyword">in</span> test_loader:</span><br><span class="line">        images, labels = data_test</span><br><span class="line">        images, labels = Variable(images).cuda(), Variable(labels).cuda()</span><br><span class="line">        output_test = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(output_test, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;correct1: &quot;</span>, correct)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test acc: &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(correct.item() /</span><br><span class="line">                                 <span class="built_in">len</span>(test_dataset)))</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    保存模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    torch.save(net.state_dict(), <span class="string">&quot;./cnn_mnist_model.pt&quot;</span>)</span><br><span class="line">    dummy_input = torch.randn(<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">    net.cpu() <span class="comment">#保存为onnx之前，先将model转为CPU模式</span></span><br><span class="line">    torch.onnx.export(net, (dummy_input), <span class="string">&quot;./net_mnist.onnx&quot;</span>, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习与机器视觉</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-硬件人的PyTorch【基础内容】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%E3%80%91/">硬件人的PyTorch【基础内容】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-03-22T12:14:17.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>==<strong>本系列博文主要根据开源的<a target="_blank" rel="noopener" href="https://github.com/datawhalechina/thorough-pytorch">thorough-pytorch</a>项目编写，感谢datawhalechina团队的dalao们分享学习经验</strong>==</p>
<h1 id="PyTorch基础简介"><a href="#PyTorch基础简介" class="headerlink" title="PyTorch基础简介"></a>PyTorch基础简介</h1><p><strong>PyTorch</strong>是由Facebook人工智能研究小组开发的一种基于<strong>Lua</strong>编写的Torch库的<strong>Python实现</strong>的<strong>深度学习库</strong>，目前被广泛应用于学术界和工业界，由于Caffe2（一个简单易用基于python的深度学习框架）并入了PyTorch，它的社区逐渐膨胀并开始影响到TensorFlow在深度学习应用框架领域的统治地位。<em>PyTorch自从提出就获得巨大的关注以及用户数量的剧增</em></p>
<blockquote>
<p>时代变了，大人</p>
<p>到现在为止PyTorch还是有不如别的框架的地方，但是框架只是给我们提供了轮子，让我们造汽车更加方便，最重要的还是我们个人的科学素养的提升</p>
<p>PyTorch提供类似NumPy的接口和调试方法，这使它容易上手且方便易用</p>
</blockquote>
<p>对于现在的边缘计算设备，跑一个由PyTorch实现的深度学习模型已经不是天方夜谭，而PyTorch除了能够实现深度学习模型的开发，还可以作为前向软件框架将一个完整的模型跑在嵌入式平台</p>
<p>最常见的嵌入式AI平台有下面几个：</p>
<ul>
<li><p>Nvidia Jetson TX2与Nvidia Jetson NX：Nvidia Jetson是老牌嵌入式AI设备之一，提供高性能的ARM Cortex-A57及以上内核，跑一个Ubuntu，再利用Cuda资源部署模型很顺滑。Nano已经很难应付一些大算力需求的模型了，因此需要使用更高端的版本</p>
<p>  Nvidia官方推荐使用的一般是TensorRT，但是对于PyTorch的兼容也在逐年完善</p>
</li>
<li><p>Atlas系列：比较常见的Atlas200，华为昇腾内核，资源相对较少，但是根据学长的评价跑PyTorch还挺行的</p>
</li>
<li><p>ASIC或FPGA：一个发展方向，硬件佬狂喜的平台。Xilinx的Pynq就能使用Zynq基于PyTorch部署AI模型，甚至可以利用硬件加速和HLS即时实现AI模型训练（虽然很拉跨）</p>
</li>
</ul>
<p>这里是学习PyTorch可以利用的资源：</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">PyTorch官方文档</a></p>
<p><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/">PyTorch官方社区</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zergtant/pytorch-handbook">Pytorch-handbook</a></p>
<p>网上的教程也都很多</p>
<h2 id="PyTorch安装"><a href="#PyTorch安装" class="headerlink" title="PyTorch安装"></a>PyTorch安装</h2><p>一般基于Anaconda安装PyTorch比较方便，正常的安装方法网上一大堆，但是这里面向的是硬件人，所以需要说明如何在嵌入式linux上安装PyTorch——毕竟安了PyTorch才能用训练好的模型</p>
<ul>
<li><p>Jetson TX2：依旧有很多资源。<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-9-0-now-available/72048">官网</a></p>
<p>  如果不嫌费事，可以直接编译源码</p>
</li>
<li><p>树莓派：目前只能通过编译源码实现了</p>
<p>  先下载源码然后切换到想用的版本</p>
<p>  需要注意：<strong>树莓派不支持cuda</strong>，所以需要设置环境变量，把cuda支持去掉</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export NO_CUDA=1</span><br><span class="line">export NO_DISTRIBUTED=1</span><br><span class="line">export NO_MKLDNN=1</span><br><span class="line">export NO_QNNPACK=1</span><br><span class="line">export NO_NNPACK=1</span><br></pre></td></tr></table></figure>

<p>  编译前记得安装依赖</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libopenblas-dev cython3 libatlas-base-dev m4 libblas-dev cmake</span><br><span class="line">pip3 install -r requirements.txt </span><br></pre></td></tr></table></figure>

<p>  最后</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 setup build</span><br></pre></td></tr></table></figure>

<p>  如果一切顺利就ok了；如果不行那就必须stackoverflow/google/百度/csdn找解决办法</p>
<p>  慢慢来罢</p>
</li>
</ul>
<p>安装成功以后需要先验证启用cuda</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>

<p> <strong>如果返回True那就是可以用Cuda了，如果返回False那就不能用Cuda，只能CPU跑</strong></p>
<p><strong>如果返回的是报错信息……查查自己的环境哪里配错了</strong></p>
<h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p><strong>几何代数</strong>中定义的<strong>张量（Tensor）</strong>是基于向量和矩阵的推广——标量是零阶张量，矢量是一阶张量，矩阵是二阶张量——张量是一个可用来表示在一些矢量、标量和其他张量之间的线性关系的多线性函数，比较数学的说法是“线性算子”</p>
<p>更广义的张量就包括RGB图片、文本数据乃至股价等数据</p>
<p><strong>计算机</strong>学意义下，<strong>张量</strong>是现代机器学习的基础，它的核心是一个数据容器，多数情况下，它包含数字，有时候它也包含字符串，但这种情况比较少</p>
<p>三维张量：时间序列</p>
<p>四维张量：图像</p>
<p>五维张量：视频</p>
<p>一个图像可以用三个独立的数据（更数学一点，可以称这些数据正交）表示，包含了它的宽度、长度、色彩通道；但在机器学习中，经常要处理不止一张图片或一篇文档，因此需要使用四维张量来描述数据，除了以上三个数据，还需要指定一个样本量。</p>
<blockquote>
<p>如果熟悉OpenCV的话会发现这里所说的张量和OpenCV中的Mat类有一定相似性</p>
</blockquote>
<p>在PyTorch中，<code>torch.Tensor类</code>是存储和变换数据的主要工具。Tensor和NumPy的多维数组非常类似，但Tensor提供GPU计算和自动求梯度等更多功能，这些使Tensor这一数据类型更加适合深度学习</p>
<p>直接使用数据，构造一个张量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([5.5000, 3.0000])</span></span><br></pre></td></tr></table></figure>

<p>基于已经存在的tensor，创建一个tensor：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个新的tensor，返回的tensor默认具有相同的 torch.dtype和torch.device</span></span><br><span class="line">x = x.new_ones(<span class="number">4</span>, <span class="number">3</span>, dtype=torch.double) </span><br><span class="line"><span class="comment"># 也可以像之前的写法 x = torch.ones(4, 3, dtype=torch.double)</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 重置数据类型</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># 结果会有一样的size</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.]], dtype=torch.float64)</span></span><br><span class="line"><span class="comment"># tensor([[ 0.2626, -0.6196,  1.0963],</span></span><br><span class="line"><span class="comment">#         [ 1.1366, -0.6543,  0.6040],</span></span><br><span class="line"><span class="comment">#         [-0.6623,  0.1115,  0.2433],</span></span><br><span class="line"><span class="comment">#         [ 1.1626, -2.3529, -0.9417]])</span></span><br></pre></td></tr></table></figure>

<p>获取它的维度信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.size())</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<p>返回的torch.Size其实就是一个tuple，⽀持所有tuple的操作</p>
<p>还有一些常见的构造Tensor的函数：</p>
<table>
<thead>
<tr>
<th align="right">函数</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td align="right">Tensor(*<em>sizes</em>)</td>
<td>基础构造函数</td>
</tr>
<tr>
<td align="right">tensor(<em>data</em>)</td>
<td>类似于np.array</td>
</tr>
<tr>
<td align="right">ones(*<em>sizes</em>)</td>
<td>构造全1矩阵</td>
</tr>
<tr>
<td align="right">zeros(*<em>sizes</em>)</td>
<td>构造零矩阵</td>
</tr>
<tr>
<td align="right">eye(*<em>sizes</em>)</td>
<td>构造单位矩阵（对角为1，其余为0）</td>
</tr>
<tr>
<td align="right">arange(<em>s,e,step</em>)</td>
<td>从s到e，步长为step</td>
</tr>
<tr>
<td align="right">linspace(<em>s,e,steps</em>)</td>
<td>从s到e，均匀分成step份</td>
</tr>
<tr>
<td align="right">rand/randn(*<em>sizes</em>)</td>
<td>随机构造</td>
</tr>
<tr>
<td align="right">normal(<em>mean,std</em>)/uniform(<em>from,to</em>)</td>
<td>正态分布/均匀分布</td>
</tr>
<tr>
<td align="right">randperm(<em>m</em>)</td>
<td>随机排列</td>
</tr>
</tbody></table>
<h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><ol>
<li><p>加法</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"><span class="built_in">print</span>(torch.add(x, y))</span><br><span class="line"></span><br><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>) </span><br><span class="line">torch.add(x, y, out=result) </span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">y.add_(x) </span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure></li>
<li><p>索引</p>
<p> 操作类似matlab和numpy</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第二列</span></span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">y = x[<span class="number">0</span>,:]</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :]) <span class="comment"># 源tensor也被改了了</span></span><br></pre></td></tr></table></figure></li>
<li><p>改变大小</p>
<p> 使用<code>torch.view</code>改变一个tensor的大小或形状（排列）</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>) <span class="comment"># -1是指这一维的维数由其他维度决定</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span></span><br></pre></td></tr></table></figure>

<p> 需要注意：view()返回的新tensor会和原来的tensor共享内存——实际上view()做的正像函数名那样，让tensor“看起来”变成了用户指定的形状（原文：仅仅是改变了对这个张量的观察角度）</p>
</li>
<li><p>广播</p>
<p> 当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">1</span>, <span class="number">3</span>).view(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = torch.arange(<span class="number">1</span>, <span class="number">4</span>).view(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br></pre></td></tr></table></figure>

<p> 由于 x 和 y 分别是1行2列和3行1列的矩阵，如果要计算 x + y ，那么 x 中第一行的2个元素被广播 (复制)到了第二行和第三行，⽽ y 中第⼀列的3个元素被广播(复制)到了第二列。如此就可以对2 个3行2列的矩阵按元素相加。</p>
</li>
</ol>
<h2 id="PyTorch自动求导机制"><a href="#PyTorch自动求导机制" class="headerlink" title="PyTorch自动求导机制"></a>PyTorch自动求导机制</h2><p>PyTorch中，所有神经网络的核心是<code>autograd</code>包，它为张量上的所有操作提供自动求导机制</p>
<p>autograd包是一个运行时定义（define-by-run）的框架，也就是说反向传播是根据代码如何运行来决定的，并且每次迭代可以是不同的。torch.Tensor类就被包含在这个包里，通过设置它的属性<code>requires_grad</code>为<code>True</code>来追踪对于张量对象的所有操作。当完成计算后可以通过调用<code>backward()</code>，来自动计算所有的梯度，这个张量的所有梯度将会自动累加到<code>grad</code>属性</p>
<p><code>Tensor</code>和<code>Function</code>互相连接生成了一个<strong>无环图</strong>(acyclic graph)，它编码了完整的计算历史。每个Tensor对象都有一个<code>grad_fn</code>属性，该属性引用了创建<code>Tensor</code>自身的<code>Function</code></p>
<p>如果需要在未开启自动求导功能情况下计算导数，可以在<code>Tensor</code>上调用<code>backward()</code>。如果<code>Tensor</code>是一个标量（即它包含一个元素的数据），则不需要为 <code>backward()</code>指定任何参数，但是如果它有更多的元素，则需要指定一个<code>gradient</code>参数——该参数是形状匹配的张量</p>
<h2 id="基于Cuda的运算加速"><a href="#基于Cuda的运算加速" class="headerlink" title="基于Cuda的运算加速"></a>基于Cuda的运算加速</h2><p>PyTorch可以通过调用Nvidia提供的Cuda接口实现运算加速，具体的方法就是将CPU中的顺序运算转换成GPU内基于Cuda核的并行运算，主要有三种方法：</p>
<ul>
<li><p>网络分布（Network partitioning）</p>
<p>  将一个模型的各个部分拆分，然后将不同的部分放入到GPU来做不同任务的计算</p>
<p>  这个方法的缺点在于不同模型组件在不同的GPU上运算，对GPU之间的传输带宽要求高，因此现在这种方法不常用</p>
</li>
<li><p>层级并行（Layer-wise partitioning）</p>
<p>  将同一层的模型拆分，让不同GPU去训练同一层模型的部分任务</p>
<p>  在需要大量的训练，同步任务加重的情况下，会出现和第一种方式一样的问题</p>
</li>
<li><p>数据并行（Data parallelism）</p>
<p>  不拆分模型，但是将输入的数据拆分：同一个模型在不同GPU中<em>训练</em>一部分数据，然后再分别<em>计算</em>一部分数据后，将输出的数据汇总，然后再反向传播，整体修正模型的参数</p>
<p>  这种方法没有上面两个方法的缺点，是现在模型训练中比较常用的方式</p>
</li>
</ul>
<p>目前主流的Nvidia GPU（GTX10系、RTX20、30系）都内置了Cuda核心，通过安装Cuda驱动、cuDNN（Cuda深度学习库）和python包就可以使用</p>
<p>Nvidia还针对嵌入式平台推出了Jetson系列SoC，集成了ARM Cortex-A处理器核心和Cuda计算单元，虽然一般不会用它训练模型，但是在模型部署以后的运算过程中还会需要大量的并行运算，使用pyTorch这个结合了训练-部署-运行的统一框架可以直接对上面的Cuda核进行调用</p>
<p>在开始下面的内容之前，推荐读者先去了解一些机器学习和深度学习的<a href="../%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.md">基本知识</a></p>
<h2 id="深度学习与传统机器学习的区别"><a href="#深度学习与传统机器学习的区别" class="headerlink" title="深度学习与传统机器学习的区别"></a>深度学习与传统机器学习的区别</h2><p>思考机器学习的总体实现步骤：首先<strong>确定训练平台</strong>和对数据进行<strong>预处理</strong>，包括统一数据格式和必要的数据变换，同时需要在数据集中划分出训练集和测试集。接下来<strong>选择模型</strong>，并<strong>设定损失函数和优化函数</strong>，以及对应的<strong>超参数</strong>。最后用模型去<strong>拟合训练集数据</strong>，并在验证集/测试集上计算模型表现。</p>
<p>深度学习和机器学习在流程上类似，但在代码实现上有较大的差异。</p>
<ul>
<li><strong>深度学习所需的样本量很大</strong>，一次加载全部数据运行可能会超出内存容量而无法实现，同时存在批训练等提高模型表现的策略，需要每次训练读取固定数量的样本送入模型中训练，因此深度学习需要专门实现数据加载</li>
<li><strong>深度神经网络层数往往较多</strong>，同时会有一些用于实现特定功能的层，因此深度神经网络往往需要<em>“逐层”搭建</em>，或预定义好可以实现特定功能的模块，再把这些模块组装起来。这种模块化构建方式能够充分保证模型的灵活性，也对代码的复用性实现提出较高要求</li>
<li>由于模型设定的灵活性，因此损失函数和优化器算法必须保证反向传播能在用户自行定义的模型结构上实现</li>
<li>代码实现中，需要使用GPU运算模型和数据，这就要求数据使用显存存储；还要保证损失函数和优化器算法能够在GPU上正常工作；完成计算后还需要把结果和中间数据转移回CPU，这就涉及到很多关于GPU的配置和操作。如果使用FPGA加速的话更需要针对硬件进行有效的并行化编程以满足部署后的加速需求</li>
</ul>
<p>深度学习中训练和验证过程最大的特点在于读入数据是按批的，每次读入一个批次的数据，放入GPU中训练，然后将损失函数反向传播回网络最前面的层，同时使用优化器调整网络参数</p>
<h2 id="PyTorch实现DNN模型"><a href="#PyTorch实现DNN模型" class="headerlink" title="PyTorch实现DNN模型"></a>PyTorch实现DNN模型</h2><p>pyTorch作为一个完善的深度学习框架，配备了很多函数去实现上面所述流程中的每个步骤</p>
<p>由于篇幅所限，<strong>这里只介绍到使用PyTorch实现深度神经网络模型</strong></p>
<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><p>在开始训练前首先导入python包。</p>
<p>下面列出了几个常用的python包和他们的功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os <span class="comment">#有关操作系统API的python接口</span></span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="comment">#matplotlib用于数据可视化处理</span></span><br><span class="line"><span class="keyword">import</span> cv2 <span class="comment">#opencv的python接口 用于顶层图像处理算法</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#numpy用于矩阵格式的数据算法</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#pandas用于处理格式化数据的读写</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment">#pytorch框架</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment">#pytorch的神经网络框架</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader <span class="comment">#pytorch的数据集处理功能</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optimizer <span class="comment">#pytorch的优化器框架</span></span><br></pre></td></tr></table></figure>

<p>同时需要设置超参数和GPU环境，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">16</span> <span class="comment">#批大小</span></span><br><span class="line">lr = <span class="number">1e-4</span> <span class="comment">#初始学习率</span></span><br><span class="line">max_epochs = <span class="number">100</span> <span class="comment">#训练次数</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;GPU配置&quot;&quot;&quot;</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0,1&#x27;</span></span><br><span class="line"><span class="comment">#使用os.environ，这种情况如果使用GPU不需要设置</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:1&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment">#使用“device”，后续对要使用GPU的变量用.to(device)即可</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;可以设置其他环境配置&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>PyTorch通过Dataset+Dataloader的方式完成数据加载</p>
<p>Dataset是定义好的数据集格式，同时也确定了数据变换的形式；Dataloader用迭代的方法的方式不断读入批次数据。</p>
<p>Dataset类主要包含三个函数：</p>
<ul>
<li><code>__init__</code>：用于向类中传入外部参数，同时定义训练集</li>
<li><code>__getitem__</code>：逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据</li>
<li><code>__len__</code>：用于返回数据集的样本数</li>
</ul>
<p>使用如下方式构建数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = datasets.ImageFolder(<span class="string">&quot;./trainer&quot;</span>, transform=data_transform) <span class="comment">#加载训练集</span></span><br><span class="line">test_dataset = datasets.ImageFolder(<span class="string">&quot;./data&quot;</span>, transform=data_transform) <span class="comment">#加载测试集</span></span><br></pre></td></tr></table></figure>

<p>这里使用了PyTorch自带的ImageFolder类，用于读取按一定结构存储的图片数据，第一个参数就描述了训练集/测试集所在目录，pytorch会从该目录中读取对应数据集进行加载；“transform”可以对图像进行一定的变换，如翻转、裁剪等操作，可自己定义</p>
<p>本质上读取步骤是使用python<strong>迭代器</strong>（iterator）完成的，因此可以直接使用next和iter方法实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(val_loader)) <span class="comment">#与上面的代码等效</span></span><br><span class="line"><span class="built_in">print</span>(images.shape)</span><br><span class="line">plt.imshow(images[<span class="number">0</span>].transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>))</span><br><span class="line">plt.show() </span><br></pre></td></tr></table></figure>

<p>如果是图片存放在一个文件夹，另有一个csv文件给出了图片名称对应的标签这种图片-标签分离的数据集吗，需要自己定义Dataset类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_dir, info_csv, image_list, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data_dir: path to image directory.</span></span><br><span class="line"><span class="string">            info_csv: path to the csv file containing image indexes</span></span><br><span class="line"><span class="string">                with corresponding labels.</span></span><br><span class="line"><span class="string">            image_list: path to the txt file contains image names to training/validation set</span></span><br><span class="line"><span class="string">            transform: optional transform to be applied on a sample.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        label_info = pd.read_csv(info_csv) <span class="comment">#使用pandas读取csv</span></span><br><span class="line">        image_file = <span class="built_in">open</span>(image_list).readlines()</span><br><span class="line">        self.data_dir = data_dir <span class="comment">#设置关键参数</span></span><br><span class="line">        self.image_file = image_file</span><br><span class="line">        self.label_info = label_info</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            index: the index of item</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            image and its labels</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        image_name = self.image_file[index].strip(<span class="string">&#x27;\n&#x27;</span>) <span class="comment">#设置文件名格式</span></span><br><span class="line">        raw_label = self.label_info.loc[self.label_info[<span class="string">&#x27;Image_index&#x27;</span>] == image_name] <span class="comment">#设置标签格式</span></span><br><span class="line">        label = raw_label.iloc[:,<span class="number">0</span>]</span><br><span class="line">        image_name = os.path.join(self.data_dir, image_name) <span class="comment">#设置文件和标签的对应</span></span><br><span class="line">        image = Image.<span class="built_in">open</span>(image_name).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_file)</span><br></pre></td></tr></table></figure>

<p>之后就可以照常调用函数进行加载了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    			train_data, </span><br><span class="line">    			batch_size=batch_size, </span><br><span class="line">    			num_workers=<span class="number">4</span>, <span class="comment">#有多少个进程用于读取数据</span></span><br><span class="line">    			shuffle=<span class="literal">True</span>, <span class="comment">#是否将读入的数据打乱</span></span><br><span class="line">    			drop_last=<span class="literal">True</span> <span class="comment">#对于样本最后一部分没有达到批次数的样本，丢弃并不再参与训练</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">val_loader = torch.utils.data.DataLoader(</span><br><span class="line">    			val_data, </span><br><span class="line">    			batch_size=batch_size, </span><br><span class="line">    			num_workers=<span class="number">4</span>, </span><br><span class="line">    			shuffle=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="实现模型"><a href="#实现模型" class="headerlink" title="实现模型"></a>实现模型</h3><p>pyTorch使用<code>nn</code>模块里提供的<code>Module</code>模型构造类，<code>Module</code>是所有神经网络模块的基类，通过继承它可以定义我们想要的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;构造多层感知机&quot;&quot;&quot;</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    	<span class="comment">#创建模型参数（结构）</span></span><br><span class="line">    	<span class="built_in">super</span>(MLP, self).__init__(**kwargs) <span class="comment">#调用MLP父类Block的构造函数</span></span><br><span class="line">		self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>) <span class="comment">#隐藏层</span></span><br><span class="line">		self.act = nn.ReLU() <span class="comment">#使用ReLu函数的激活层</span></span><br><span class="line">		self.output = nn.Linear(<span class="number">256</span>,<span class="number">10</span>) <span class="comment">#输出层</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    	<span class="comment">#定义模型的前向计算（正向传播），即如何根据输入x计算返回所需要的模型输出</span></span><br><span class="line">		o = self.act(self.hidden(x))</span><br><span class="line">		<span class="keyword">return</span> self.output(o)</span><br></pre></td></tr></table></figure>

<p>因为上面介绍过的pyTorch自动求导机制，MLP类中无须定义反向传播函数，框架会经由自动求梯度自动生成反向传播所需的backward 函数。</p>
<p>对MLP类实例化后就得到了所需的模型变量，下面的代码展示了如何使用net对象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">2</span>,<span class="number">784</span>) <span class="comment">#设置一个随机张量用于检验模型</span></span><br><span class="line">net = MLP() <span class="comment">#实例化</span></span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line">net(X) <span class="comment">#调用MLP继承自Module类的call函数以调用forward函数实现前向计算</span></span><br></pre></td></tr></table></figure>

<p>上面的代码会返回</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">print(net)的结果：输出模型结构</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">MLP(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (act): ReLU()</span><br><span class="line">  (output): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">net(X)的结果：输出计算后得到的输出张量</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">tensor([[ <span class="number">0.0149</span>, -<span class="number">0.2641</span>, -<span class="number">0.0040</span>,  <span class="number">0.0945</span>, -<span class="number">0.1277</span>, -<span class="number">0.0092</span>,  <span class="number">0.0343</span>,  <span class="number">0.0627</span>,</span><br><span class="line">         -<span class="number">0.1742</span>,  <span class="number">0.1866</span>],</span><br><span class="line">        [ <span class="number">0.0738</span>, -<span class="number">0.1409</span>,  <span class="number">0.0790</span>,  <span class="number">0.0597</span>, -<span class="number">0.1572</span>,  <span class="number">0.0479</span>, -<span class="number">0.0519</span>,  <span class="number">0.0211</span>,</span><br><span class="line">         -<span class="number">0.1435</span>,  <span class="number">0.1958</span>]], grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></table></figure>

<p>需要注意：<strong>Module类是一个可以自由设置的组件，它的子类可以是层（如pytorch内置的Linear类就是这样），也可以是一个完整的模型（如这里的MLP类），还可以是模型的一个部分</strong></p>
<p>PyTorch的模型实现思路就是用Module类的子类构建完整模型</p>
<h3 id="实现层"><a href="#实现层" class="headerlink" title="实现层"></a>实现层</h3><p>Module的最基础功能就是定义一个<strong>不含模型参数的自定义层</strong>，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义层&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">		<span class="built_in">super</span>(MyLayer, self).__init__(**kwargs) <span class="comment">#调用MLP父类Block的构造函数</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;自定义的前向传播函数&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> x - x.mean() <span class="comment">#x-\bar&#123;x&#125;</span></span><br></pre></td></tr></table></figure>

<p>该自定义层设置的函数即<br>$$<br>ouput = x - \bar{x}<br>$$<br><strong>输入值减去均值后输出</strong></p>
<p>测试代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">layer = MyLayer() <span class="comment">#实例化</span></span><br><span class="line">layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>)) <span class="comment">#设置输入是一个浮点数张量</span></span><br></pre></td></tr></table></figure>

<p>输入取平均得3，可以预料到会输出一个同样是5行的张量[-2,-1,0,1,2]</p>
<p>实际验证结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-<span class="number">2.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br></pre></td></tr></table></figure>

<p>其中有<code>.</code>是因为输入数据类型是浮点数</p>
<p>进一步还可以自定义<strong>含模型参数的自定义层</strong>。其中的模型参数可以通过训练学出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer_Dense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义层&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;这里选择构建一个全连接层Dense&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyLayer_Dense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        <span class="comment">#遍历所有参数得到一个参数列表</span></span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line">        <span class="comment">#在每个参数后面追加参数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment">#前向传播函数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">net = MyListDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<p>其中使用了<code>Parameter</code>类，它是<code>Tensor</code>的子类，<strong>如果一个Tensor被识别为Parameter，它就会被自动添加到模型的参数列表中</strong>。在自定义含参数模型的层时应该把参数定义成Parameter，同时<strong>可以用<code>ParameterList</code>和<code>ParameterDict</code>分别定义参数组成的列表和字典</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用字典构建的上述全连接层&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyDictDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">                <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">                <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;) <span class="comment">#新增参数字典项</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line">net = MyDictDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<h3 id="CNN中常见层的PyTorch实现"><a href="#CNN中常见层的PyTorch实现" class="headerlink" title="CNN中常见层的PyTorch实现"></a>CNN中常见层的PyTorch实现</h3><ul>
<li><p>二维卷积层</p>
<p>  二维卷积层将输入和<strong>卷积核</strong>做<strong>互相关运算</strong>，并加上一个<strong>标量偏差</strong>来得到输出</p>
<blockquote>
<p>卷积的概念在这里不再介绍，如有需要可以参考之前的博文《神经网络基础概念》</p>
</blockquote>
<p>  卷积层的模型参数包括了<strong>卷积核</strong>和<strong>标量偏差</strong>。训练模型时，我们通常先对卷积核随机初始化，然后通过反向传播不断迭代卷积核和偏差来让达到损失函数最小</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span>(<span class="params">X, K</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;卷积运算（二维互相关运算）&quot;&quot;&quot;</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    X, K = X.<span class="built_in">float</span>(), K.<span class="built_in">float</span>()</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;二维卷积层&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Conv2D, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias <span class="comment">#卷积运算+标量偏差</span></span><br></pre></td></tr></table></figure>

<p>  卷积窗口形状是$p \times q$的卷积层被称为$p \times q$卷积层，说明卷积核的高和宽分别为$p$和$q$</p>
<p>  下面我们大小为3x3的二维卷积层，然后设输⼊高和宽两侧的填充数<strong>分别为1</strong>。那么给定一个长和宽均为8的输入张量，可以发现输出的高和宽也是8</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span>‘</span><br><span class="line">    <span class="comment">#定义一个函数来计算卷积层</span></span><br><span class="line">    <span class="comment">#它对输入和输出做相应的升维和降维</span></span><br><span class="line">  	X = X.view((<span class="number">1</span>, <span class="number">1</span>) + X.shape) <span class="comment">#(1, 1)代表批大小和通道数</span></span><br><span class="line">	Y = conv2d(X) <span class="comment">#进行卷积</span></span><br><span class="line">	<span class="keyword">return</span> Y.view(Y.shape[<span class="number">2</span>:]) <span class="comment">#排除不关心的前两维（批量和通道），输出张量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#注意这里是两侧分别填充1行/列，等同于在两侧一共填充2⾏或列</span></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出</span></span><br><span class="line"><span class="string">torch.Size([8, 8])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>  当卷积核的高和宽不同时，我们也可以通过设置高和宽上不同的填充数使输出和输入具有相同的高和宽；同时也可以自行设置步幅</p>
<p>  总体来说，<strong>填充可以增加输出的高和宽，步幅可以减小输出的高和宽</strong></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), padding=(<span class="number">0</span>, <span class="number">1</span>), stride=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出</span></span><br><span class="line"><span class="string">torch.Size([2, 2])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>池化层</p>
<p>  池化层专用于对输入数据的一个固定形状窗口（即<strong>池化窗口</strong>）中的元素计算输出，这里直接计算池化窗口内元素的最大值或者平均值，分别叫做<strong>最大池化算子</strong>或<strong>平均池化算子</strong></p>
<p>  它通过降低特征图的分片率获得特征图里具有空间不变性的特征</p>
<p>  下面将实现一个二维最大池化层，池化窗口会从输入的最上方开始，按从左往右、从上往下的顺序遍历数组，当池化窗口滑动到某位置时，窗口的输入数组最大值即输出数组中相应位置的元素</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="复现论文"><a href="#复现论文" class="headerlink" title="复现论文"></a>复现论文</h3><p>学习深度学习最基本的方法就是复现经典论文中的模型，并对他们进行训练验证</p>
<p>下面构造几个经典的模型作为本篇博文的总结</p>
<blockquote>
<p>可以<strong>使用nn包来构建神经网络</strong>，实际上<strong>它依赖于autograd包来定义模型并实现自动求导功能</strong>，一个Module子类实现的模型总包含模型各个层的结构和一个forward(input)方法用于最终的模型输出</p>
<p>这就是使用PyTorch构建模型的总体思路</p>
</blockquote>
<ul>
<li><p><strong>LeNet</strong>：手写数字识别</p>
<p>  它的结构很简单，是经典的<strong>前馈神经网络</strong>，也是最早出现的CNN模型之一</p>
<p>  <img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%E3%80%91/3.4.1.png" alt="3.4.1"></p>
<p>  LeNet由7层网络组成，上图中输入的原始图像大小是32×32像素，<strong>卷积层用Ci表示，池化层用Si表示，全连接层用Fi表示</strong></p>
<p>  根据上图来定义LeNet的网络结构：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">	<span class="string">&quot;&quot;&quot;定义LeNet类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        在这里定义CNN的结构和要调用的参数（占用内存空间）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>) <span class="comment">#从INPUT到C1的卷积层</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>) <span class="comment">#从C1到C3的卷积层</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>) <span class="comment">#从S4到C5的全连接层</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>) <span class="comment">#从C5到F6的全连接层</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>) <span class="comment">#从F6到输出的全连接层</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        定义前向传播函数</span></span><br><span class="line"><span class="string">        在这里定义具体的实现，参考上面的网络结构图即可</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment">#先经过conv1这个卷积层C1</span></span><br><span class="line">        <span class="comment">#再进入ReLu激活层</span></span><br><span class="line">        <span class="comment">#最后经过2x2池化核的最大池化层S2</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment">#与上面同理，先进入conv2代表的卷积层C3</span></span><br><span class="line">        <span class="comment">#通过ReLu函数激活后</span></span><br><span class="line">        <span class="comment">#再进入2x2池化核的最大池化层S4</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        <span class="comment">#通过num_flat_features除去批处理维度的其他所有维度</span></span><br><span class="line">        <span class="comment">#由于S4层的大小为5×5，而该层的卷积核大小也是5×5</span></span><br><span class="line">        <span class="comment">#因此特征图大小为(5-5+1)×(5-5+1)=1×1，该层刚好变成了全连接层同时也是卷积层C5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        <span class="comment">#先通过S4到C5的全连接层fc1</span></span><br><span class="line">        <span class="comment">#再通过ReLu函数</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment">#这是从C5到F6的全连接层fc2</span></span><br><span class="line">        <span class="comment">#和上面一样</span></span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment">#最后通过全连接层fc3输出</span></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment">#除去批处理维度的其他所有维度</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size: <span class="comment">#全连接</span></span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出网络结构</span></span><br><span class="line"><span class="string">Net(</span></span><br><span class="line"><span class="string">  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class="line"><span class="string">  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class="line"><span class="string">  (fc1): Linear(in_features=400, out_features=120, bias=True)</span></span><br><span class="line"><span class="string">  (fc2): Linear(in_features=120, out_features=84, bias=True)</span></span><br><span class="line"><span class="string">  (fc3): Linear(in_features=84, out_features=10, bias=True))</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>  一个模型的可学习参数可以通过<code>net.parameters()</code>返回</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(params))</span><br><span class="line"><span class="built_in">print</span>(params[<span class="number">0</span>].size())  <span class="comment">#conv1的权重</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出</span></span><br><span class="line"><span class="string">10</span></span><br><span class="line"><span class="string">torch.Size([6, 1, 5, 5])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>  注意：<strong>LeNet的输入是32x32的张量（图像矩阵）。如果使用MNIST数据集来训练这个网络，要提前把图片大小重新调整到32x32</strong></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure>

<p>  在下一轮开始前需要清零所有参数的梯度缓存，然后进行随机梯度的反向传播：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<p>  注意：<code>torch.nn</code>只支持小批量处理 (mini-batches），整个<code>torch.nn</code>包只支持小批量样本的输入，不支持单个样本的输入。如果是一个单独的样本，需要使用<code>input.unsqueeze(0)</code>来添加一个“假的”批大小</p>
</li>
<li><p><strong>AlexNet</strong>：早期的深度学习分类算法</p>
<p>  <a href="https://link.zhihu.com/?target=http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">原论文下载</a></p>
<p>  AlexNet中包含了几个比较新的技术点，也首次在CNN中成功应用了ReLU、Dropout和LRN等技术。同时AlexNet也使用了GPU进行运算加速。它将LeNet的思想发扬光大，把CNN的基本原理应用到了很深很宽的网络中</p>
<p>  <img src="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%E3%80%91/3.4.2.png" alt="3.4.2"></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            <span class="comment">#这里使用了Sequential方法实现连续层的实现</span></span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            <span class="comment">#连续3个卷积层，且使用更小的卷积窗口</span></span><br><span class="line">            <span class="comment">#除了最后的卷积层外，进一步增大了输出通道数</span></span><br><span class="line">            <span class="comment">#前两个卷积层后不使用池化层来减小输入的高和宽</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#这里全连接层的输出个数比LeNet中的大数倍</span></span><br><span class="line">        <span class="comment">#需要使用丢弃层来缓解过拟合</span></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            <span class="comment">#由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>), <span class="comment">#输出层</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img) <span class="comment">#提取特征图</span></span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>)) <span class="comment">#输出</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<p>  上面的代码给出了AlexNet的结构，读者可以自行测试</p>
</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习与机器视觉</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/22/%E7%A1%AC%E4%BB%B6%E4%BA%BA%E7%9A%84PyTorch%E3%80%90%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-现代C语言3" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/19/%E7%8E%B0%E4%BB%A3C%E8%AF%AD%E8%A8%803/">现代C语言3</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/19/%E7%8E%B0%E4%BB%A3C%E8%AF%AD%E8%A8%803/" class="archive-article-date">
  	<time datetime="2022-03-19T05:40:30.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="使用C语言进行嵌入式开发"><a href="#使用C语言进行嵌入式开发" class="headerlink" title="使用C语言进行嵌入式开发"></a>使用C语言进行嵌入式开发</h1><p>C语言语法简单、容易上手，因此常被各大高校用于编程教学或与电子信息专业结合作为单片机的主要开发语言。通常的编程是指在桌面级平台、服务器平台、PC或其他通用计算机上进行程序编写，在现代的编程环境下，C常常被诟病“老套、不美观、面向过程、难以使用”，但事实上C11标准引入以来，Linux生态中C语言扮演着重要角色。同时，在更广阔的嵌入式开发领域，C语言作为一个有着靠近底层、高效率，而又不依靠汇编实现的编程语言发挥着重要作用</p>
<p>以上都是废话</p>
<p><strong>这篇博文主要介绍使用C语言进行嵌入式开发的一些基础要点，并简要介绍常用的工具</strong></p>
<p>本篇建立在前两篇《现代C语言》的基础上，不再介绍gcc、make、cmake、kconfig等工具</p>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">C语言进阶</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/19/%E7%8E%B0%E4%BB%A3C%E8%AF%AD%E8%A8%803/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-经典排序算法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/18/%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/">经典排序算法</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/18/%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" class="archive-article-date">
  	<time datetime="2022-03-18T07:22:59.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-18</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/2022/03/18/%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/1.png" alt="img"></p>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">杂项</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/18/%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-一生一芯学习笔记1【Verilator】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/03/01/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E3%80%90Verilator%E3%80%91/">一生一芯学习笔记1【Verilator】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/03/01/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E3%80%90Verilator%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-03-01T10:55:24.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-03-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Verilator入门"><a href="#Verilator入门" class="headerlink" title="Verilator入门"></a>Verilator入门</h1><p>今年2月底报名了22年第四期<a target="_blank" rel="noopener" href="https://docs.ysyx.org/">一生一芯</a>，借着这个机会学学前端设计相关内容</p>
<p>个人目标暂且定为：</p>
<ul>
<li>设计一个五级流水，可挂载协处理器的RV32IMF指令集处理器</li>
<li>在两到三期内完成一生一芯规定的基础流片指标</li>
<li>挂载一个可用于图像处理的加速器</li>
<li>使用AMBA总线在片上集成一套用于水下机器人控制的外设（包括GPIO、UART、PWM、DCMI、DMA、MAC）</li>
<li>将自制的RTOS开发完毕并部署在SoC上</li>
<li>将芯片部署在一台ROV中并实现完整的机器人控制、水下图像识别任务</li>
</ul>
<p>希望能在本科期间把这一套东西做完……</p>
<p>22年第四期一生一芯要求在开始之前需要自己搭建基于verilator+gtkwave的验证环境（预学习阶段），这里简单记录一下这部分的要点内容（<strong>教程不允许将自己代码发布到公开网站，这里遵守要求仅记录知识点和bug解决思路</strong>）</p>
<p>这系列博文与其说是笔记，不如说是对这段学习经历的总结？</p>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">一生一芯</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/03/01/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E3%80%90Verilator%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-经典CV算法" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/02/25/%E7%BB%8F%E5%85%B8CV%E7%AE%97%E6%B3%95/">经典CV算法</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/02/25/%E7%BB%8F%E5%85%B8CV%E7%AE%97%E6%B3%95/" class="archive-article-date">
  	<time datetime="2022-02-25T07:42:37.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-02-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="OpenCV与经典视觉算法"><a href="#OpenCV与经典视觉算法" class="headerlink" title="OpenCV与经典视觉算法"></a>OpenCV与经典视觉算法</h1><p>本博客参考《OpenCV3编程入门》（<em>毛星云</em> 冷雪飞 电子工业出版社）写成（还有来自毛星云dalao在csdn写成的系列博文），本篇内容旨在总结<em>嵌入式设备</em>中常用（基础）的机器视觉算法（上面书籍的前七章），代码主要使用OpenCV实现，部分代码可以直接在OpenMV或类似的嵌入式平台上部署</p>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习与机器视觉</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/02/25/%E7%BB%8F%E5%85%B8CV%E7%AE%97%E6%B3%95/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-FPGA学习笔记4【AMBA总线】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/">FPGA学习笔记4【AMBA总线】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-02-06T12:47:44.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-02-06</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="AMBA总线规范"><a href="#AMBA总线规范" class="headerlink" title="AMBA总线规范"></a>AMBA总线规范</h1><p>AMBA规范由ARM公司制定，用于SoC内IP互联</p>
<p>AMBA即（Advanced Microcontroller Bus Architecture，AMBA）规范是一种开放式标准片上互联规范，用于连接和管理片上系统中的各个功能模块（IP）。显而易见，AMBA协议是一套片上总线协议，一般来说其信号线数量都比较多——ARM通过这套协议规定了各种信号线的作用，并没有规定信号线的位宽和具体实现，所以说每个芯片中的AMBA都可能具有不同的架构</p>
<p>AMBA中有以下几个主要接口：</p>
<ul>
<li>高级外设总线APB：用于低速低功耗外设连接</li>
<li>高级高性能总线AHB：用于高速外设连接</li>
<li>高级可扩展接口AXI：最普遍使用的高性能总线</li>
<li>高级跟踪总线ATB：用于在芯片外围移动跟踪数据</li>
<li>AXI一致性扩展接口ACE：用于移动设备的大小核之间高速连接</li>
<li>相关集线器接口CHI：用于网络和服务器设备的高带宽高性能数据传输</li>
</ul>
<h2 id="APB规范"><a href="#APB规范" class="headerlink" title="APB规范"></a>APB规范</h2><p><strong>在APB总线中，唯一的主机为APB总线桥，其它外设都是从机</strong>。因此APB总线不需要有一个像AHB一样的仲裁器以及其它控制器，因此通常APB总线可看做由<strong>APB总线桥</strong>和<strong>APB上的从设备</strong>两部分组成。APB总线通常是AHB或者ASB系统总线（已经过时的总线）的扩展，便于外设链接到系统总线上，AHB和APB之间就使用APB总线桥来链接</p>
<p>APB规定<strong>所有信号必须在时钟上升沿进行传递</strong></p>
<p>APB总线包含8根信号线，都是以H开头，区别其他的AMBA总线信号：</p>
<ul>
<li><strong>PCLK</strong>：总线时钟，由总线时钟源提供</li>
<li><strong>PRESETn</strong>：复位信号，低电平有效，由系统总线复位信号提供</li>
<li><strong>PADDR</strong>：总线地址信号，由外设APB总线桥提供</li>
<li><strong>PPROT</strong>：保护信号，用于表示普通的、剥夺的或安全保护级别</li>
<li><strong>PSELx</strong>：总线选择信号，该信号表示选中某个从设备，<em>每个从设备都应该有一个PSELx信号</em></li>
<li><strong>PENABLE</strong>：总线数据传输使能，用于触发APB总线的访问周期</li>
<li><strong>PWRITE</strong>：总线访问方向信号，信号拉高表示APB写访问；信号拉低表示APB读访问</li>
<li><strong>PWDATA</strong>：写数据信号，使用该信号线驱动写数据总线</li>
<li><strong>PRDATA</strong>：读数据信号，在读周期时从所选择的从设备驱动该总线，宽度受限（最高32位）</li>
<li><strong>PSTRB</strong>：写选通信号，用于表示写传输时更新哪个字节通道。每8位使用一个PSTRB信号线控制。在读传输时，写选通信号不活动</li>
<li><strong>PREADY</strong>：总线准备信号，从设备控制该信号来扩展APB传输</li>
<li><strong>PSLVERR</strong>：总线错误信号，用于表示传输失败。外设可以不使用PSLVERR引脚，在外设不包含该引脚时，APB桥的数据应适当拉低</li>
</ul>
<p>以上总线结构可以和下文相互参考理解</p>
<h3 id="读写时序"><a href="#读写时序" class="headerlink" title="读写时序"></a>读写时序</h3><ol>
<li><p>无等待状态写</p>
<ol>
<li>需要一个<strong>建立周期</strong>寄存PADDR、PWDATA、PWRITE、PSEL，这些信号会在PCLK上升沿完成寄存</li>
<li>在第二个周期，PENABLE和PREADY寄存，PENABLE表示传输<strong>访问周期</strong>开始；PREADY表示PCLK的下一个上升沿从设备可以完成传输</li>
<li>第三个周期完成之前，PADDR、PWDATA和控制信号会一直保持有效</li>
<li>第四个周期，PENABLE和PSEL变成无效，等待下一个传输开始</li>
</ol>
<p> <img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/20200511103914209.png" alt="img"></p>
</li>
<li><p>有等待状态写</p>
<ol>
<li>在访问周期开始时，PENABLE为高时，可以通过拉低PREADY来扩展传输</li>
<li>PREADY拉低后，可以添加两个传输周期</li>
<li>新添加的周期也可以是有等待状态的，即可以通过拉低PREADY来无限延长传输周期</li>
</ol>
</li>
<li><p>无等待状态读</p>
<p> 基本时序和无等待状态写类似，但是使用PRDATA作为信号传输线，在读传输结束之前，从设备必须主动提供数据</p>
<p> <img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5ZndpbGw=,size_16,color_FFFFFF,t_70.png" alt="img"></p>
</li>
<li><p>有等待状态读</p>
<p> 与有等待状态写类似，可以通过拉低PREADY来实现延长传输周期</p>
</li>
</ol>
<p>事实上，除了写信号有效性相反外，APB读操作时序和写操作时序非常相似。特别地，如果写操作之后跟随着读操作或者相反，那么需要 3个等待周期来完成读操作。通常的情况下，不会有读操作之后紧跟着写操作的发生，因为两者之间CPU会进行取指操作——更重要的是指令存储器不太可能直接挂在APB总线上</p>
<h3 id="错误响应"><a href="#错误响应" class="headerlink" title="错误响应"></a>错误响应</h3><p>传输中使用<em>PSLVERR</em>信号来指示APB总线传输的错误条件。</p>
<p>为了防止读写交易过程中发生错误，当PSEL、PENABLE、PREADY都为高时，PSLVERR有效</p>
<p>当外设接收到一个错误时，写交易并不会更新外设内的寄存器；而当读交易能够返回无效的数据，对于读错误，并不会要求外设将数据总线驱动置0</p>
<h3 id="APB控制状态机"><a href="#APB控制状态机" class="headerlink" title="APB控制状态机"></a>APB控制状态机</h3><p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/1000019445-6369948876516550714068695.png" alt="blob.png"></p>
<p>APB总线状态机如上图所示</p>
<ul>
<li><strong>IDLE</strong>：空闲状态，APB总线默认处于此状态</li>
<li><strong>SETUP</strong>：建立状态，当请求传输时，PSEL=1。在一次传输中，该状态只会保留一个时钟周期</li>
<li><strong>ACCESS</strong>：访问状态，PSEL=1，PENABLE=1。要求地址信号、选择信号、读/写数据信号保持不变。准备信号PREADY决定了是否从ACCESS状态退出（PREADY=0，保持；PREADY=1，退出，如果此使没有其他传输请求，就返回IDLE，否则继续进入SETUP）</li>
</ul>
<p>APB的每次传输均需<strong>消耗2个周期的时间</strong></p>
<h2 id="AHB规范"><a href="#AHB规范" class="headerlink" title="AHB规范"></a>AHB规范</h2><p>APB总线用于低速低功耗的情况，一般只是用他来控制外设的寄存器；而AHB总线则通常用于更高速的情况——基于ARM核的MCU一般都使用AHB连接内核和APB总线。</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/123F15311_0.png" alt="一个典型的AHB系统总线的结构示意图"></p>
<p>如上图所示，典型AMBA总线系统就是这样，ARM核、片上RAM、DTCM/ITCM等高带宽内存、DMA设备这些需要高速传输的设备挂载到AHB总线上；APB总线连接低速的定时器、GPIO、串口、片外总线控制器等外设；AHB总线和APB总线间通过总线桥相连不过近年来，随着外设和片外总线速度越来越高（MCU逐渐整合DSP功能），一些高速定时器、高速GPIO都会被直接挂载到AHB总线上</p>
<p>与APB总线协议不同，AHB总线具有以下特性：</p>
<ul>
<li>高性能：支持流水线操作和分割交易（分割交易含义在后文给出）</li>
<li>支持猝发传输（也就是突发传输Burst Mode）：在一次传输内向固定地址传输多个数据字，也就是说可以一次传输一个地址和一批地址连续的数据</li>
<li>可由多个总线主设备控制</li>
</ul>
<h3 id="总线互联"><a href="#总线互联" class="headerlink" title="总线互联"></a>总线互联</h3><p>AHB协议规范只规定了总线的通信时序，并没有规定总线的具体实现方法和互联机制，于是可以在AHB基础上采用多路复用器互联、总线矩阵等等实现思路</p>
<p>最基本的互联方式就是<strong>多路复用器互联</strong>：使用两个MUX分别控制地址信号线和读写数据信号线的传输，使用一个译码器实现主设备控制读写数据和响应信号的切换，所有总线设备都由总线仲裁器控制。如下图所示</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/361409-20190212140153881-540841057.png" alt="image"></p>
<h3 id="总线操作流程"><a href="#总线操作流程" class="headerlink" title="总线操作流程"></a>总线操作流程</h3><ol>
<li><p><strong>总线仲裁</strong></p>
<p> 在开始传输前，主设备需要先向AHB总线仲裁器提出使用申请，总线仲裁器随后会根据仲裁逻辑授权主设备进行总线访问。</p>
<p> 在总线仲裁之前，允许一个主设备以特定的猝发方式完成所有传输。但是为了避免产生过长的仲裁延迟，仲裁器可以将一个猝发分解，这个操作称为<strong>分割交易</strong></p>
</li>
<li><p>猝发传输</p>
<p> 在总线仲裁完毕后，主设备会启动AHB传输，在这个阶段可以使用两种被允许的猝发传输逻辑（不知道该怎么翻译比较好）：</p>
<ul>
<li>增量猝发：在地址边界不回卷</li>
<li>回卷猝发：在特殊的地址边界回卷</li>
</ul>
</li>
<li><p>每次传输由<em>地址和控制周期</em>与<em>数据周期</em>构成</p>
<p> 在传输期间，所有从设备必须采样地址</p>
</li>
<li><p>从设备回报</p>
<p> 在每次传输期间，从设备使用响应信号HRESP[1:0]显示状态，可选的状态如下：</p>
<ul>
<li>OKAY：传输正常，当HREADY=2’b11时，表示传输成功结束</li>
<li>ERROR：传输失败。表示发生传输错误</li>
<li>RETRY和SPLIT：表示不能立即完成传输，但是总线主设备应该继续尝试传输</li>
</ul>
<p> 如果发生分割交易，主设备会在这个时间段向仲裁器提出仲裁以便完成猝发传输中剩余的操作</p>
</li>
</ol>
<h3 id="读写时序-1"><a href="#读写时序-1" class="headerlink" title="读写时序"></a>读写时序</h3><p>如果没有猝发传输或等待，主设备会发起一个普通传输，分成两个主要部分</p>
<ol>
<li><p>地址周期</p>
<p> 这个环节持续一个时钟周期，在第一个HCLK上升沿，主设备会先驱动总线上的地址和控制信号并保持</p>
</li>
<li><p>数据周期</p>
<p> 在下一个时钟上升沿，从设备采集总线上的地址和控制信号</p>
<p> 从设备完成采集后立刻驱动响应信号线，在第三个时钟上升沿时，主设备再采样这个响应</p>
<p> 数据周期可以持续几个时钟周期，因为在任何一个传输中，从设备都可能插入等待状态。在读传输的等待状态中，从设备不必提供有效数据，在将要完成传输前提供有效数据即可</p>
<p> 为了允许更高性能的操作，AHB总线允许<strong>流水线操作</strong>：在前一个数据周期结尾，一旦主设备采样完成就可以启动地址周期，驱动总线的地址和控制信号，这样从设备就能够获得充足时间响应一次传输</p>
</li>
</ol>
<h3 id="AHB总线的信号线种类"><a href="#AHB总线的信号线种类" class="headerlink" title="AHB总线的信号线种类"></a>AHB总线的信号线种类</h3><p>AHB总线的信号都是以H开头，区别其他的AMBA总线信号</p>
<table>
<thead>
<tr>
<th>信号名</th>
<th>信号源</th>
<th>信号功能</th>
</tr>
</thead>
<tbody><tr>
<td>HCLK</td>
<td>总线时钟源</td>
<td>总线时钟信号，上升沿有效</td>
</tr>
<tr>
<td>HRESET</td>
<td>系统复位</td>
<td>系统reset信号，低电平有效</td>
</tr>
<tr>
<td>HADDR[31:0]</td>
<td>主设备</td>
<td>32位系统地址总线</td>
</tr>
<tr>
<td>HTRANS[1:0]</td>
<td>主设备</td>
<td>传输类型，一共有四种类型：NONSEQ、SEQ、IDLE、BUSY</td>
</tr>
<tr>
<td>HSIZE[2:0]</td>
<td>主设备</td>
<td>每次传输的数据大小。以字节为单位。最高支持1024位</td>
</tr>
<tr>
<td>HBURST[2:0]</td>
<td>主设备</td>
<td>猝发传输类型，一共有8种</td>
</tr>
<tr>
<td>HPROT[3:0]</td>
<td>主设备</td>
<td>保护控制信号</td>
</tr>
<tr>
<td>HWDATA[31:0]</td>
<td>主设备</td>
<td>写数据信号线</td>
</tr>
<tr>
<td>HSELx</td>
<td>译码器</td>
<td>从设备选择信号线</td>
</tr>
<tr>
<td>HRDATA[31:0]</td>
<td>从设备</td>
<td>读数据信号线</td>
</tr>
<tr>
<td>HREADY</td>
<td>从设备</td>
<td>传输完成信号。当这个信号线拉高时，表示当前传输完成；从设备也可以通过拉低这个信号线来延长一个传输。注意：从设备需要2个HREADY信号线，其中一个作为输出，一个作为输入</td>
</tr>
<tr>
<td>HRESP[1:0]</td>
<td>从设备</td>
<td>从设备给主设备的响应信号。一共有四种：OKAY、ERROR、RETRY、SPLIT</td>
</tr>
<tr>
<td></td>
<td>下面是仲裁器的信号</td>
<td></td>
</tr>
<tr>
<td>HBUSREQx</td>
<td>主设备</td>
<td>主设备请求信号线。主设备通过该信号线向仲裁器发出获得总线使用权的请求信号，最多支持16个主设备</td>
</tr>
<tr>
<td>HLOCKx</td>
<td>主设备</td>
<td>总线锁定信号线。如果一个主设备希望自己在传输期间不丢掉总线，则需要向仲裁器发送这个锁定信号</td>
</tr>
<tr>
<td>HGRANTx</td>
<td>仲裁器</td>
<td>授权信号线。仲裁器的仲裁结果会通过该信号线传送给每一个主设备。当HREADY和HGRANTx同时为高时，主设备被允许获取系统总线</td>
</tr>
<tr>
<td>HMASTER[3:0]</td>
<td>仲裁器</td>
<td>主设备ID信号线。仲裁器为每一个主设备分配对应的的ID，用来给多路选择器提供选择信号和为SPLIT操作提供控制信号</td>
</tr>
<tr>
<td>HMASTLOCK</td>
<td>仲裁器</td>
<td>总线阻塞信号。表示当前的主设备正在执行锁定操作。该信号和HMASTER时序相同</td>
</tr>
<tr>
<td>HSPLITx[15:0]</td>
<td>具有SPLIT操作的从设备</td>
<td>仲裁器SPLIT控制信号</td>
</tr>
</tbody></table>
<h3 id="传输类型编码"><a href="#传输类型编码" class="headerlink" title="传输类型编码"></a>传输类型编码</h3><p>每个传输都有独立的传输类型，由HTRANS[1:0]表示</p>
<ul>
<li>00：<strong>IDLE</strong>（空闲）。表示没有请求数据传输，这个信号表示总线主设备获得了总线控制权但是并没有执行数据传输。这种情况下从设备需要返回一个零状态等待信号OKAY并忽略本次传输</li>
<li>01：<strong>BUSY</strong>（忙碌）。忙传输，允许总线主设备在猝发传输中插入空闲周期。一般这种类型表示主设备正在连续执行猝发传输但不能立即产生下一次传输。当一个主设备触发该类型时，要求它驱动带地址和控制信号必须反映猝发中的下一次传输；从设备则应该忽略这种传输</li>
<li>10：<strong>NONSEQ</strong>（非连续）。一次猝发的第一次传输或者一个独立传输，表示地址与控制信号和前一次传输无关。总线上的单个传输会被看作一次猝发传输，随意使用这个信号会导致传输不连续</li>
<li>11：<strong>SEQ</strong>（连续）。表示在一次猝发传输中剩下的传输是连续传输且与前一次传输有关，控制信息和前一次传输时一样，地址等于<em>前一次</em>传输的地址加上传输大小（以字节为单位）。在回卷猝发的情况下，传输地址需要在地址边界处回卷，<em>回卷值等于传输大小乘传输次数</em></li>
</ul>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Transfer type: HTRANS[1:0]</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HTRANS_IDLE   2&#x27;b00</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HTRANS_BUSY   2&#x27;b01</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HTRANS_NONSEQ 2&#x27;b10</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HTRANS_SEQ    2&#x27;b11</span></span><br></pre></td></tr></table></figure>

<h3 id="传输控制信号"><a href="#传输控制信号" class="headerlink" title="传输控制信号"></a>传输控制信号</h3><p>每次AHB传输中，都会使用一组控制信号线提供传输的附加信息，要求他们的时序和地址总线时序严格一致，并且信号在猝发传输中保持不变</p>
<p>下面是用到的控制信号线</p>
<ol>
<li><p>传输方向HWRITE</p>
<p> HWRITE=1时，表示写传输，主设备会将数据放到写数据总线HWDATA[31:0]</p>
<p> HWRITE=0时，表示读传输，从设备会将数据放到读数据总线HRDATA[31:0]</p>
 <figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Write signal: HWRITE</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HWRITE_READ  1&#x27;b0</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HWRITE_WRITE 1&#x27;b1</span></span><br></pre></td></tr></table></figure></li>
<li><p>传输大小HSIZE</p>
<p> 使用HSIZE[2:0]表示传输宽度，该信号线和HBURST[2:0]信号一起决定了回卷猝发的地址边界</p>
<p> 有以下几种选项：</p>
<ul>
<li>000：8位，字节</li>
<li>001：16位，半字</li>
<li>010：32位，字</li>
<li>011：64位，双字</li>
<li>100：128位</li>
<li>101：256位</li>
<li>110：512位</li>
<li>111：1024位</li>
</ul>
 <figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Transfer size: HSIZE[2:0]</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_8    3&#x27;b000</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_16   3&#x27;b001</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_32   3&#x27;b010</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_64   3&#x27;b011</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_128  3&#x27;b100</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_256  3&#x27;b101</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_512  3&#x27;b110</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HSIZE_1024 3&#x27;b111</span></span><br></pre></td></tr></table></figure></li>
<li><p>保护信号HPROT[3:0]</p>
<p> 用于提供附加信息，一般提供给能执行不同保护级别的模块使用，表示传输时一次预取指或数据访问、特权模式、用户模式访问，或带高速缓存/无高速缓存</p>
<p> 设备在没有严格要求的情况下不需要使用该信号</p>
<ul>
<li>HPROT[0]：0，预取指；1，数据访问</li>
<li>HPROT[1]：0，用户模式；1，特权模式</li>
<li>HPROT[2]：0，无缓冲；1，带缓冲</li>
<li>HPROT[3]：0，无高速缓存；1，带高速缓存</li>
</ul>
</li>
</ol>
<h3 id="猝发操作详解"><a href="#猝发操作详解" class="headerlink" title="猝发操作详解"></a>猝发操作详解</h3><p>AHB协议规定了4、8、16拍的基本猝发和未定长度的猝发。协议默认支持两种猝发方式</p>
<ul>
<li><p>递增猝发：访问连续地址且猝发中每次传输的地址仅是前一次地址的一个递增和回卷</p>
</li>
<li><p>回卷猝发：若传输起始地址并未和猝发中的字节总数对齐，那么传输地址会在达到边界处回卷</p>
<blockquote>
<p>一个4拍回卷猝发的字访问将在16字节边界回卷，因此若传输起始地址是0x34，那么它会包括0x34、0x38、0x3C和0x30四个地址，其中0x30是由回卷导致的</p>
</blockquote>
</li>
</ul>
<p>通过HBURST[2:0]信号线指示促发信息，具有8种可能的猝发类型：</p>
<ul>
<li>000：单一传输</li>
<li>001：未定长度的递增猝发</li>
<li>010：4拍回卷猝发</li>
<li>011：4拍递增猝发</li>
<li>100：8拍回卷猝发</li>
<li>101：8拍递增猝发</li>
<li>110：16拍回卷猝发</li>
<li>111：16拍递增猝发</li>
</ul>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Bus operation: HBURST[2:0]</span></span><br><span class="line"><span class="comment">// Note: 猝发传输不能跨越1kB的地址边界</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_SINGLE 3&#x27;b000</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_INCR   3&#x27;b001</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_WRAP4  3&#x27;b010</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_INCR4  3&#x27;b011</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_WRAP8  3&#x27;b100</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_INCR8  3&#x27;b101</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_WRAP16 3&#x27;b110</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HBURST_INCR16 3&#x27;b111</span></span><br></pre></td></tr></table></figure>

<p>特别注意：<strong>猝发不能超过1KB的地址边界</strong></p>
<p>猝发大小表示猝发的节拍数量而不是一次猝发传输的实际字节数——<strong>每拍字节数是由HSIZE[2:0]指示的</strong></p>
<p>对于一个从设备而言，可以在不允许完成一个猝发的特殊情况下提前终止猝发传输。一般通过监控<em>HTRANS信号</em>完成，如果产生一个非连续或空闲传输，则表示新的猝发开始，需要保证在此之前终止了前一次的猝发传输，并向主设备提供过连续或忙指示</p>
<h3 id="地址译码器"><a href="#地址译码器" class="headerlink" title="地址译码器"></a>地址译码器</h3><p><strong>AHB总线上的从设备一般共用一个中央地址译码器提供选择信号HSELx</strong></p>
<p>一般要求这个译码器尽可能简单可靠，避免复杂的逻辑实现高速操作</p>
<p>协议规定：</p>
<ol>
<li>从设备只能在HREADY为高时采样地址总线信号、控制信号和HSELx信号</li>
<li>当HSELx信号为高时，表示当前传输完成，因此在特定情况下会在HREADY为低时采样HSELx信号，但会在传输完成后更改选中的从设备</li>
<li>总线主设备不能执行超过1KB地址边界的递增传输</li>
<li>在存储器映射不能完全填满存储空间时，需要设置一个额外的默认从设备来让主设备访问不存在地址空间时提供响应，要求至少实现以下两个响应<ul>
<li>ERROR：当传输访问不存在的地址空间或出现非连续传输时</li>
<li>OKAY：当空闲或访问不存在的地址空间（默认从设备）时</li>
</ul>
</li>
</ol>
<h3 id="从设备传输响应时序"><a href="#从设备传输响应时序" class="headerlink" title="从设备传输响应时序"></a>从设备传输响应时序</h3><p>从设备使用HREADY信号来扩展一次AHB传输的数据周期——HREADY=0，表示要扩展传输；否则表示传输完成，同时可以结合从设备输出的HRESP[1:0]信号表示传输情况</p>
<p>协议推荐从设备不要插入多余16个扩展传输等待状态，否则单个访问会将总线锁定较长的时钟周期，影响片上数据传输——<em>不过这并不是强制规定</em></p>
<p>HRESP[1:0]具有以下四种状态：</p>
<ul>
<li>00：OKAY，表示成功完成传输</li>
<li>01：ERROR，表示发生传输错误，出现错误条件时，需要两个周期响应</li>
<li>10：RETRY，表示传输并未完成，总线主设备应重新传输直到完成，要求两个周期响应。仲裁器收到该指示后会继续使用原有的优先级方案，重新为申请总线的设备排序并进行调度分配</li>
<li>11：SPLIT，表示未成功完成传输，下次授权总线主设备访问总线时再尝试传输；当能够完成传输时，从设备会将请求代替主设备访问总线，要求两个周期响应。仲裁器收到该指示后会调整优先级方案来让其他主机的传输优先完成，随后再进行当前主机的传输</li>
</ul>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Transfer response: HRESP[1:0]</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HRESP_OKAY  2&#x27;b00</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HRESP_ERROR 2&#x27;b01</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HRESP_RETRY 2&#x27;b10</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">define</span> HRESP_SPLIT 2&#x27;b11</span></span><br></pre></td></tr></table></figure>

<p>上面要求两个周期响应的情况被称为<strong>双周期响应</strong>，需要在最后一个传输的前一个周期驱动HRESP[1:0]表示扩展一个周期。而如果从设备还需要更多周期，应该在传输开始时将HREADY信号拉低，同时响应OKAY。双周期响应允许主设备有足够时间取消该地址，并且在下次传输前驱动HTRANS[1:0]为空闲传输</p>
<p>特别的，如果从设备出现错误响应，主设备可以选择取消猝发中剩下的传输，但这并不是强制规定</p>
<p>由于分割传输的“<strong>释放总线</strong>”特性，可以更有效地实现长数据分批传输</p>
<h3 id="数据总线"><a href="#数据总线" class="headerlink" title="数据总线"></a>数据总线</h3><p>AHB协议要求读写数据总线至少为32位，但是允许用户扩展数据位，一些高性能核使用64位的读写数据总线</p>
<ol>
<li><p>写数据总线HWDATA</p>
<p> 写数据总线依赖主设备驱动，如果使用扩展传输，总线主设备需要保持数据有效知道HREADY为高（表示传输完成）为止。要求传输与数据宽度相等的数据宽度对齐：字传输对其到字边界，半字传输对齐到半字边界，以此类推。</p>
<p> 同时需要区分大端和小端序，二者的有效字节通道是正好相反的，如下图所示</p>
<p> <img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/361409-20190523105301974-714158567.png" alt="https://img2018.cnblogs.com/blog/361409/201905/361409-20190523105301974-714158567.png"></p>
<p> 显而易见，<strong>不要把端序不同的设备接到同一个总线上</strong></p>
</li>
<li><p>读数据总线HRDATA</p>
<p> 从设备负责驱动读数据总线，当HREADY拉低，可以扩展读传输过程，从设备只需在传输的<em>最后一个周期</em>提供有效数据。</p>
<p> 对于小于总线宽度的数据传输，从设备需要在有效的字节通道提供有效数据，总线主设备负责从这些通道内选择数据采样，且<strong>只有传输以OKAY响应结束时，从设备才需要提供有效数据</strong></p>
</li>
<li><p>端结构</p>
<p> <strong>AHB总线不支持动态端结构</strong></p>
<p> 同时对于其他具有相似性能的总线，也不推荐支持动态端结构——因为它的面积和功耗开销太大了</p>
</li>
</ol>
<h3 id="仲裁器"><a href="#仲裁器" class="headerlink" title="仲裁器"></a>仲裁器</h3><p><strong>设置总线仲裁器的目的是保证任意时刻只有一个主设备在占用总线</strong>。仲裁器会检测多个主设备的总线使用需求，确定当前请求总线的主设备中优先级最高的主设备，并动态调节来自从设备的分割传输请求。</p>
<p>仲裁器作为总线主控设备使用以下信号线：</p>
<ul>
<li><p>HBUSREQx总线请求信号：主设备会使用该信号请求访问总线</p>
<p>  因为一个系统中最多有16个独立的总线主设备，因此x在0~15之间</p>
</li>
<li><p>HLOCKx总线同步锁定信号：用于通知仲裁器主设备正在进行不可分割的传输</p>
<p>  一旦该信号拉高，仲裁器就不应该授权其他主设备访问总线</p>
<p>  主设备应当保证寻址完毕之前HLOCKx信号在一个周期内有效，防止仲裁器改变授权信号</p>
</li>
<li><p>HGRANTx授权信号：由仲裁器产生，高电平有效，表示对应的主设备优先级最高，享有总线控制权，优先考虑锁定传输和分割传输。</p>
<p>  得到该信号确认的主设备，在HCLK上升沿时HREADY为高——当HREADY和HGRANTx同时为高时，主设备被允许获取系统总线</p>
</li>
<li><p>HMASTER[3:0]主设备ID信号线：表示当前被授权使用总线的主设备编号</p>
<p>  特别情况，具有分割传输能力的从设备也能请求主设备号，以便提示仲裁器能够完成一个分割传输的主设备</p>
</li>
<li><p>HMASTLOCK锁定信号：指示某个传输是一个锁定序列的一部分</p>
<p>  表示当前的主设备正在执行锁定操作</p>
</li>
<li><p>HSPLIT[15:0]分割传输信号：从设备用来指示能够完成一个分割传输的总线主设备，仲裁器获取该信号线上数据来向对应的主设备提供授权完成分割传输</p>
</li>
</ul>
<p>下面是仲裁器的一个实现</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">AMBA 总线规范是一种多主总线标准。因此</span></span><br><span class="line"><span class="comment">需要一个总线仲裁器来确保只有一个总线主机可以访问</span></span><br><span class="line"><span class="comment">任何特定时间的总线。这个仲裁器最多可以支持三个总线主设备</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">module</span> ahb_arbiter3</span><br><span class="line">(</span><br><span class="line">  <span class="comment">//主设备0</span></span><br><span class="line">  <span class="keyword">input</span> HBUSREQx0,</span><br><span class="line">  <span class="keyword">input</span> HLOCKx0,</span><br><span class="line">  <span class="keyword">output</span> <span class="keyword">reg</span> HGRANTx0,</span><br><span class="line">  <span class="comment">//主设备1</span></span><br><span class="line">  <span class="keyword">input</span> HBUSREQx1,</span><br><span class="line">  <span class="keyword">input</span> HLOCKx1,</span><br><span class="line">  <span class="keyword">output</span> <span class="keyword">reg</span> HGRANTx1,</span><br><span class="line">  <span class="comment">//主设备2</span></span><br><span class="line">  <span class="keyword">input</span> HBUSREQx2,</span><br><span class="line">  <span class="keyword">input</span> HLOCKx2,</span><br><span class="line">  <span class="keyword">output</span> <span class="keyword">reg</span> HGRANTx2,</span><br><span class="line">  <span class="comment">//主设备3</span></span><br><span class="line">  <span class="keyword">input</span> HBUSREQx3,</span><br><span class="line">  <span class="keyword">input</span> HLOCKx3,</span><br><span class="line">  <span class="keyword">output</span> <span class="keyword">reg</span> HGRANTx3,</span><br><span class="line"></span><br><span class="line">  <span class="comment">//地址和控制信号线</span></span><br><span class="line">  <span class="keyword">input</span> [<span class="number">31</span>:<span class="number">0</span>] HADDR,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">3</span>:<span class="number">0</span>] HSPLIT,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">1</span>:<span class="number">0</span>] HTRANS,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">2</span>:<span class="number">0</span>] HBURST,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">1</span>:<span class="number">0</span>] HRESP,</span><br><span class="line">  <span class="keyword">input</span> HREADY,</span><br><span class="line"></span><br><span class="line">  <span class="comment">//总线复位</span></span><br><span class="line">  <span class="keyword">input</span> HRESETn,</span><br><span class="line">  <span class="comment">//总线时钟</span></span><br><span class="line">  <span class="keyword">input</span> HCLK,</span><br><span class="line"></span><br><span class="line">  <span class="comment">//从设备信号线</span></span><br><span class="line">  <span class="comment">// MASTER: which signal owns the current address phase</span></span><br><span class="line">  <span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>] HMASTER,</span><br><span class="line">  <span class="comment">// MASTERD: which signal owns the current data phase</span></span><br><span class="line">  <span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>] HMASTERD,</span><br><span class="line">  <span class="keyword">output</span> HMASTLOCK</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>这是仲裁器的总线接口</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">本地寄存器</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">//输出本地寄存器</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] HMASTER_l;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] HMASTERD_l;</span><br><span class="line"><span class="keyword">reg</span> HMASTLOCK_l; <span class="comment">//HMASTLOCK的缓存</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制信号</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>] grant; <span class="comment">//标明现在拥有总线控制权的设备</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>] next_grant; <span class="comment">//下个传输周期拥有总线控制权的设备</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> is_degrant; <span class="comment">//确认下个周期是否是上个传输的最后一个周期以便总线能安全使用</span></span><br><span class="line"><span class="keyword">wire</span> is_locked; <span class="comment">//确认当前传输是否被锁定</span></span><br><span class="line"><span class="keyword">reg</span> is_fixed_length; <span class="comment">//确认当前传输数据长度是否固定</span></span><br><span class="line"><span class="keyword">reg</span> is_split; <span class="comment">//从设备是否返回一个分割交易信号</span></span><br><span class="line"><span class="keyword">reg</span> is_retry; <span class="comment">//从设备是否返回一个RETRY信号</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] count; <span class="comment">//传输时钟周期的计数器</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] next_count; <span class="comment">//下个传输周期还剩下多少时钟周期结束</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] req_mask; <span class="comment">//屏蔽来自分割交易主设备的请求，如果对应位是1则不会屏蔽；如果是0则会屏蔽并需要等待从设备的HSPLIT</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] next_req_mask; <span class="comment">//下个周期的req_mask值</span></span><br></pre></td></tr></table></figure>

<p>上面部分统一实现了仲裁器内部的控制寄存器和输出寄存器，带<code>next</code>的寄存器变量都是用于预存下个周期的数据，该部分代码相当于经典三段式状态机的第一段</p>
<p>实现上，仲裁器输出可以用多个mealy状态机的组合实现：在一次普通传输中，总线主设备首先通过HBUSREQx请求总线使用权，仲裁器在HCLK上升沿采样请求，随后在内部判断访问总线的下一个主设备。仲裁器通过HGRANTx信号线和HMASTER[3:0]信号线授权主设备。主设备获取授权后可以选择通过拉高HLOCKx信号锁定访问总线，仲裁器在HCLK上升沿采样该信号后会锁定总线并阻止其他设备获取总线控制权。所有操作都要发生在总线空闲也就是HRADY为高时</p>
<p>需要解释一下<strong>默认主设备</strong>的概念：每个系统必须包含一个默认主设备——如果其他所有主设备不能使用总线，则授权主设备使用总线且它只能执行空闲传输；如果其他主设备都在等待分割交易，则必须给默认主设备授权总线。这是为了便于降低功耗总线。下面的代码就是默认主设备的输出——默认主设备会一直保持下面的总线驱动方式</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assign</span> HTRANS = <span class="meta">`HTRANS_IDLE;</span></span><br><span class="line"><span class="keyword">assign</span> HLOCK = <span class="number">1&#x27;b0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> HADDR = <span class="number">32&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> HWRITE = <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> HSIZE = <span class="number">3&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> HBURST = <span class="number">3&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> HWDATA = <span class="number">32&#x27;b0</span>;</span><br></pre></td></tr></table></figure>

<p>特别地，在猝发传输时，仲裁器授权主设备获取总线没有必要继续请求总线以便完成传输，仲裁器应使用HBURST[2:0]信号决定主设备请求的传输个数，如果主设备希望在当前正在进行的传输之后执行另一个猝发，主设备需要在猝发中重新拉高HLOCKx；对于未定长度的猝发，主设备应继续请求，直到已经开始最后一次传输。猝发传输结束时，最后一个地址采样的同时仲裁器会采样新的HGRANTx数据</p>
<p>下面是负责控制输出的电路</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">输出逻辑</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">//HMASTLOCK信号生成电路</span></span><br><span class="line"><span class="comment">//当且仅当总线被授权且对应的HLOCKx拉高时才允许HMASTLOCK生成</span></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span>((HGRANTx0 &amp;&amp; HLOCKx0) || (HGRANTx1 &amp;&amp; HLOCKx1) || (HGRANTx2 &amp;&amp; HLOCKx2) || (HGRANTx3 &amp;&amp; HLOCKx3)) </span><br><span class="line">  <span class="keyword">begin</span></span><br><span class="line">    HMASTLOCK_l = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  <span class="keyword">begin</span></span><br><span class="line">    HMASTLOCK_l = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> HMASTLOCK = HMASTLOCK_l;</span><br><span class="line"></span><br><span class="line"><span class="comment">//HGRANTx信号生成电路:</span></span><br><span class="line"><span class="comment">//基于以下优先级（从高到低）实现</span></span><br><span class="line"><span class="comment">//Master 3</span></span><br><span class="line"><span class="comment">//Master 0 （Dummy Master）</span></span><br><span class="line"><span class="comment">//Master 2</span></span><br><span class="line"><span class="comment">//Master 1</span></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span> <span class="comment">//状态转移部分</span></span><br><span class="line">    <span class="keyword">if</span>(!HRESETn) <span class="keyword">begin</span> <span class="comment">//复位</span></span><br><span class="line">    grant &lt;= <span class="number">2&#x27;b01</span>; <span class="comment">//默认主设备</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span>((is_locked &amp;&amp; (HRESP == <span class="meta">`HRESP_SPLIT)) ||</span></span><br><span class="line">       (HGRANTx1 &amp;&amp; HRESP == <span class="meta">`HRESP_SPLIT &amp;&amp; !HBUSREQx2 &amp;&amp; !HBUSREQx3) ||</span></span><br><span class="line">       (req_mask == <span class="number">4&#x27;b0</span>)) <span class="keyword">begin</span></span><br><span class="line">      grant &lt;= <span class="number">2&#x27;b00</span>; <span class="comment">//Master 2 次高优先级 但一直作为Dummy Master保留</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(is_degrant) <span class="keyword">begin</span></span><br><span class="line">      grant &lt;= next_grant; <span class="comment">//如果总线正被占用则轮转切换grant状态</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span> <span class="comment">//状态更新部分</span></span><br><span class="line">  <span class="keyword">if</span>(HBUSREQx3 &amp;&amp; req_mask[<span class="number">3</span>]) <span class="keyword">begin</span></span><br><span class="line">    next_grant = <span class="number">4&#x27;h3</span>; <span class="comment">//Master 3 最高优先级</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(HBUSREQx2 &amp;&amp; req_mask[<span class="number">2</span>]) <span class="keyword">begin</span></span><br><span class="line">    next_grant = <span class="number">4&#x27;h2</span>; <span class="comment">//Master 2 第三优先级</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    next_grant = <span class="number">4&#x27;h1</span>; <span class="comment">//Master 1 最低优先级</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span> <span class="comment">//输出部分</span></span><br><span class="line">  <span class="comment">//清除旧值</span></span><br><span class="line">  HGRANTx0 = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  HGRANTx1 = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  HGRANTx2 = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  HGRANTx3 = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="comment">//输出新值</span></span><br><span class="line">  <span class="keyword">case</span>(grant) </span><br><span class="line">    <span class="number">4&#x27;h3</span>: HGRANTx3 = <span class="number">1&#x27;b1</span>;</span><br><span class="line">    <span class="number">4&#x27;h2</span>: HGRANTx2 = <span class="number">1&#x27;b1</span>;</span><br><span class="line">    <span class="number">4&#x27;h1</span>: HGRANTx1 = <span class="number">1&#x27;b1</span>;</span><br><span class="line">    <span class="number">4&#x27;h0</span>: HGRANTx0 = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">endcase</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//HMASTER信号生成电路</span></span><br><span class="line"><span class="comment">//当且仅当HREADY拉高时再更新HMASTER；切换grant信号则表示最终传输已经被从设备缓存，新的主设备接管了总线</span></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span>(!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    HMASTER_l &lt;= <span class="number">2&#x27;b01</span>; <span class="comment">//默认主设备</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(HREADY) <span class="keyword">begin</span></span><br><span class="line">    HMASTER_l &lt;= grant;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> HMASTER = HMASTER_l;</span><br><span class="line"></span><br><span class="line"><span class="comment">//HMASTERD信号生成电路</span></span><br><span class="line"><span class="comment">//只有当HREADY拉高时更新HMASTERD</span></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span> <span class="comment">//输出部分</span></span><br><span class="line">  <span class="keyword">if</span>(!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    HMASTERD_l &lt;= <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span>(HREADY) <span class="keyword">begin</span></span><br><span class="line">      HMASTERD_l &lt;= HMASTER_l;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      HMASTERD_l &lt;= HMASTERD_l;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> HMASTERD = HMASTERD_l;</span><br></pre></td></tr></table></figure>

<p>下面是各个信号的判断电路</p>
<p>总线需要监视来自各个主设备的HLOCKx信号，为了确定主设备何时希望执行一个锁定连续传输</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//is_degrant判断逻辑</span></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span>((HGRANTx0 &amp;&amp; !HBUSREQx0) || </span><br><span class="line">     (HGRANTx1 &amp;&amp; !HBUSREQx1) ||</span><br><span class="line">     (HGRANTx2 &amp;&amp; !HBUSREQx2) ||</span><br><span class="line">     (HGRANTx3 &amp;&amp; !HBUSREQx3)) <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b1</span>; </span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="comment">//如果当前传输为IDLE状态，可以安全地将总线授权给主设备</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(HTRANS == <span class="meta">`HTRANS_IDLE)</span></span><br><span class="line">  <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="comment">//如果当前传输是定长且下次传输是最终传输周期，可以安全地将总线授权给主设备</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(is_fixed_length &amp;&amp; </span><br><span class="line">         (!is_locked) &amp;&amp; </span><br><span class="line">         (next_count == <span class="number">1&#x27;b0</span> || next_count == <span class="number">1&#x27;b1</span>)) <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="comment">//如果出现分割交易，可以安全地将总线授权给主设备</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(is_split) <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="comment">//如果出现分割RETRY信号，可以安全地将总线授权给主设备</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(is_retry) <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="comment">//否则不可以将总线授权给主设备</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    is_degrant = <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//is_locked信号控制电路</span></span><br><span class="line"><span class="keyword">assign</span> is_locked = (HGRANTx0 &amp;&amp; HLOCKx0) ||</span><br><span class="line">                   (HGRANTx1 &amp;&amp; HLOCKx1) ||</span><br><span class="line">                   (HGRANTx2 &amp;&amp; HLOCKx2) ||</span><br><span class="line">                   (HGRANTx3 &amp;&amp; HLOCKx3);</span><br><span class="line"><span class="comment">//出现任意一个设备占用总线时都会锁住总线</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//is_fixed_length信号控制电路（时序逻辑）</span></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span>(!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    is_fixed_length &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      <span class="keyword">case</span>(HBURST)  <span class="comment">//分状态控制</span></span><br><span class="line">      <span class="meta">`HBURST_SINGLE: is_fixed_length &lt;= 1&#x27;b0;</span></span><br><span class="line">      <span class="meta">`HBURST_INCR:   is_fixed_length &lt;= 1&#x27;b0;</span></span><br><span class="line">      <span class="meta">`HBURST_WRAP4:  is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">      <span class="meta">`HBURST_INCR4:  is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">      <span class="meta">`HBURST_WRAP8:  is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">      <span class="meta">`HBURST_INCR8:  is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">      <span class="meta">`HBURST_WRAP16: is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">      <span class="meta">`HBURST_INCR16: is_fixed_length &lt;= 1&#x27;b1;</span></span><br><span class="line">    <span class="keyword">endcase</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//is_split、is_retry控制电路（时序逻辑）</span></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span> (!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    is_split &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      <span class="keyword">if</span>(HRESP == <span class="meta">`HRESP_SPLIT) begin //直接读取从设备回传信号</span></span><br><span class="line">      is_split &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      is_split &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">if</span> (!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    is_retry &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span>(HRESP == <span class="meta">`HRESP_RETRY) begin</span></span><br><span class="line">      is_retry &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      is_retry &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p>下面的电路则是典型的计数器处理状态机</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//next_count计算和更新电路（状态机）</span></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line">  <span class="comment">//如果HTRANS为NONSEQ，重置计数器</span></span><br><span class="line">  <span class="keyword">if</span>(HTRANS == <span class="meta">`HTRANS_NONSEQ)</span></span><br><span class="line">  <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span>(HREADY) <span class="keyword">begin</span> <span class="comment">//如果HREADY拉高，则当前传输会在下一时钟周期结束，计数器清零后-1</span></span><br><span class="line">      <span class="keyword">case</span>(HBURST) <span class="comment">//猝发传输控制</span></span><br><span class="line">        <span class="meta">`HBURST_SINGLE: next_count = 6&#x27;h0;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR:   next_count = 6&#x27;h20; //使用第6位指示INCR</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP4:  next_count = 6&#x27;h3;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR4:  next_count = 6&#x27;h3;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP8:  next_count = 6&#x27;h7;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR8:  next_count = 6&#x27;h7;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP16: next_count = 6&#x27;hf;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP16: next_count = 6&#x27;hf;</span></span><br><span class="line">      <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      <span class="keyword">case</span>(HBURST)</span><br><span class="line">        <span class="meta">`HBURST_SINGLE: next_count = 6&#x27;h1;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR:   next_count = 6&#x27;h20; //使用第6位指示INCR</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP4:  next_count = 6&#x27;h4;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR4:  next_count = 6&#x27;h4;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP8:  next_count = 6&#x27;h8;</span></span><br><span class="line">        <span class="meta">`HBURST_INCR8:  next_count = 6&#x27;h8;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP16: next_count = 6&#x27;h10;</span></span><br><span class="line">        <span class="meta">`HBURST_WRAP16: next_count = 6&#x27;h10;</span></span><br><span class="line">      <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(HTRANS == <span class="meta">`HTRANS_BUSY)begin //BUSY状态</span></span><br><span class="line">    next_count = count;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(HTRANS == <span class="meta">`HTRANS_IDLE)begin //IDLE状态</span></span><br><span class="line">    next_count = <span class="number">6&#x27;h0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span> <span class="comment">//普通情况基于上一周期的计数器进行计算</span></span><br><span class="line">    <span class="keyword">if</span>(HREADY) <span class="keyword">begin</span></span><br><span class="line">      <span class="keyword">if</span>(count[<span class="number">5</span>] == <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">        next_count = count; <span class="comment">//如果计数器溢出则保留值</span></span><br><span class="line">      <span class="keyword">end</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">        next_count = count - <span class="number">1</span>; <span class="comment">//正常情况-1</span></span><br><span class="line">      <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">      next_count = count; <span class="comment">//如果HREADY拉低，说明传输未开始，不改变计数器</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span> <span class="comment">//更新/复位计数器</span></span><br><span class="line">  <span class="keyword">if</span> (!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    count &lt;= <span class="number">6&#x27;b0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    count &lt;= next_count;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p>下面的电路负责分割交易时的<strong>主设备掩码</strong>处理</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//next_req_mask和req_mask计算/更新电路</span></span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line">  <span class="comment">//基于HSPLIT信号控制HBUSREQ掩码</span></span><br><span class="line">  next_req_mask = req_mask | HSPLIT;</span><br><span class="line">  <span class="keyword">if</span>(is_split) <span class="keyword">begin</span> <span class="comment">//如果出现分割交易则使用掩码机制</span></span><br><span class="line">    <span class="keyword">case</span>(HMASTER)</span><br><span class="line">      <span class="number">2&#x27;b00</span>: next_req_mask[<span class="number">0</span>] = <span class="number">1&#x27;b0</span>;</span><br><span class="line">      <span class="number">2&#x27;b01</span>: next_req_mask[<span class="number">1</span>] = <span class="number">1&#x27;b0</span>;</span><br><span class="line">      <span class="number">2&#x27;b10</span>: next_req_mask[<span class="number">2</span>] = <span class="number">1&#x27;b0</span>;</span><br><span class="line">      <span class="number">2&#x27;b11</span>: next_req_mask[<span class="number">3</span>] = <span class="number">1&#x27;b0</span>;</span><br><span class="line">    <span class="keyword">endcase</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> HCLK <span class="keyword">or</span> <span class="keyword">negedge</span> HRESETn) <span class="keyword">begin</span> <span class="comment">//复位与更新req_mask</span></span><br><span class="line">  <span class="keyword">if</span>(!HRESETn) <span class="keyword">begin</span></span><br><span class="line">    req_mask &lt;= <span class="number">4&#x27;b1111</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">    req_mask &lt;= next_req_mask;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p><strong>早期猝发停止</strong>：在一般的猝发传输结束之前，仲裁器不会把总线移交给一个新的主设备，但是如果仲裁器决定必须提前终止猝发来防止过长的总线访问时间时，他可能在一个猝发完成之前将总线授权转移给另一个总线主设备。这种情况称为早期猝发停止。主设备授权总线控制权后，它<strong>必须重新断言总线请求（包括HBURST、HTRANS信号）</strong>来完成猝发传输。</p>
<p>协议建议但并不规定：主设备在任何锁定连续传输之后插入一个空闲传输，以提供给仲裁器在准备另一个猝发传输之前改变总线授权的机会</p>
<h3 id="分割交易详解"><a href="#分割交易详解" class="headerlink" title="分割交易详解"></a>分割交易详解</h3><p><strong>分割交易</strong>也称为<strong>分割传输</strong>：根据从设备的响应操作来分割主设备，这是从设备响应速度不够的无奈之举</p>
<p>在分割传输时，可以通过给从设备提供地址和合适的数据来提高总线的整体使用率——<strong>当且仅当从设备认为传输执行将占据大量时钟周期的情况下会使用分割传输机制</strong>。分割传输信号由从设备提供——这一点上文中已经提到过，但还是需要强调主设备并没有分割传输的命令权——仲裁器则负责监视分割传输信号并在内部屏蔽分割传输主设备的任何请求，这就是主设备掩码的作用</p>
<p>从设备需要通过断言合适的地址位来让仲裁器识别到哪个主设备应该使用分割传输；如果系统中具有多个从设备，它们的信号需要经过或门传输给仲裁器。<em>协议建议将所有分割传输能力的从设备设计成支持最大十六个主设备</em></p>
<p>分割传输的执行顺序如下：</p>
<ol>
<li>主设备发起总线传输</li>
<li>如果从设备发现需要很多周期才能获取到主设备需要的数据，他将发起分割传输</li>
<li>才能够设备广播一个标记表示正在使用总线的主设备，仲裁器将记录该号码并在一段时间后重新发起传输</li>
<li>仲裁器授权其他主设备使用总线</li>
<li>如果其他主设备也出现了分割传输需求，仲裁器允许嵌套的分割传输</li>
<li>从设备准备完成传输时拉高HSPLITx信号里的对应位</li>
<li>每个时钟信号HCLK上升沿，仲裁器读取HSPLITx信号并重新授权对应的访问总线的主设备</li>
<li>仲裁器授权分割的主设备总线后，主设备可以重新尝试传输，如果有优先级更高的设备正在使用总线，分割传输不能打断</li>
<li>完成传输</li>
</ol>
<p>AHB总线只允许每个总线主设备有一个未完成的处理，如果任何主设备模块能够处理多个未完成的处理，那么它需要为每个未完成的设置额外的请求和授权信号；但是一个具有分割交易能力的从设备可能会接收比他能并发处理传输还要多的传输请求，如果从设备出现来不及响应的请求，可以只记录主设备号来发出分割响应，之后等到设备完成当前工作再接收传输</p>
<p>分割交易时，需要警惕<strong>总线死锁</strong>的情况：如果多个不同的主设备同时尝试访问同一个从设备，但从设备发出的分割或重试响应表示从设备不能处理他们时，就可能发生死锁。为了避免死锁，<strong>仲裁器</strong>应当<strong>记录已经处理和发出分割响应的传输请求</strong>，<strong>从设备</strong>不需要锁存地址和控制信息，而是<strong>记录特定主机设备发出的传输请求</strong>，这样同时可以避免总线不安全因素：如果从设备不记录应该发出分割交易请求的主机，外来设备有可能在总线分割交易中间获取从设备回传的数据。</p>
<blockquote>
<p>协议建议：分割交易中从设备发现主设备号不一致时，应该选择以下几种响应方式之一：</p>
<ul>
<li>错误响应</li>
<li>传输对应信号给仲裁器</li>
<li>向总控制器发出系统级中断</li>
<li>执行完全的系统复位</li>
</ul>
</blockquote>
<h3 id="AHB位宽"><a href="#AHB位宽" class="headerlink" title="AHB位宽"></a>AHB位宽</h3><p>AHB协议允许8、16、32、64、128、256、512、1024位宽的数据总线，但是大多数用户都会使用32位~256位的总线</p>
<p>只需要在总线外部加入转换逻辑即可实现宽总线传输数据到窄从设备</p>
<blockquote>
<p>传输时需要保证：</p>
<ol>
<li>将待传输数据分成两份</li>
<li>同时传输；两份数据，但让从设备串行接收数据</li>
</ol>
<p>这样就能实现1/2位宽的数据传输</p>
</blockquote>
<p>但是如果要在窄总线上实现宽从设备的数据传输，就要在外部转换逻辑的基础上加入<strong>多路选择输入总线</strong>和<strong>复制输出总线</strong>电路，也就是说主设备的指令译码和从设备的返回数据都要加入额外的处理电路</p>
<h3 id="AHB复位"><a href="#AHB复位" class="headerlink" title="AHB复位"></a>AHB复位</h3><p>HRESETn是AHB协议中唯一的低电平有效信号，并且是所有总线设备的复位源</p>
<p><strong>AHB总线采用异步复位</strong></p>
<p>但是复位可以在HCLK上升沿被同步撤销</p>
<p>需要保证复位期间主设备信号可控，并使用HTRANS[1:0]信号表示空闲</p>
<h3 id="一套开源的AHB总线实现"><a href="#一套开源的AHB总线实现" class="headerlink" title="一套开源的AHB总线实现"></a>一套开源的AHB总线实现</h3><p>GitHub上的一套开源<a target="_blank" rel="noopener" href="https://github.com/Lianghao-Yuan/AHB_Bus_Matrix">AHB总线实现</a>，<strong>上述代码全部以该repo为例</strong></p>
<p>感兴趣的读者可以翻阅源码</p>
<h2 id="AXI4规范"><a href="#AXI4规范" class="headerlink" title="AXI4规范"></a>AXI4规范</h2><p>AHB总线和APB总线相关内容可以参考知乎上面@<a target="_blank" rel="noopener" href="https://www.zhihu.com/people/orangeofcat">桔里猫</a>的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/157808097?from_voters_page=true">简介</a>，本博文也参考了一部分</p>
<p>下面再介绍现代FPGA/SoC中常用的AMBA总线：AXI4总线</p>
<p>对比AHB总线，AXI4总线通过<strong>猝发交易机制</strong>实现了高性能、大吞吐量的数据传输。</p>
<p>AXI即Advanced Extensible Interface，是ARM公司提出的AMBA3.0协议中最重要的一种总线协议，面向高性能、高带宽、低延迟的片内传输。它的地址位、控制位、数据位相互分离，支持不对齐的数据传输，同时在猝发交易（突发传输）中只需要首地址。</p>
<p>AXI重要的三个特色就是分离的读写数据通道、支持显著传输访问和乱序访问、更加容易就行时序收敛，满足超高性能和复杂SoC设计的需求</p>
<p>AXI4包括了三个子总线协议：</p>
<ul>
<li>标准<strong>AXI4</strong>：针对高性能内存映射（high-performance memory-map）要求实现的总线</li>
<li><strong>AXI4-Lite</strong>：用于低吞吐率内存映射（low-throughput memory-map）通信的总线（例如操作控制和状态寄存器），具有较小的面积，其中与标准AXI4最大的区别是突发（猝发）传输不受支持</li>
<li><strong>AXI-Stream</strong>：用于高速数据流的总线（比如视频信号、大量传感器数据通信），完全移除了对地址周期的要求，并允许无限制的突发数据尺寸，大大强化了传输周期的吞吐量，但是失去了内存地址映射的能力</li>
</ul>
<blockquote>
<p>可以这样理解三个协议：</p>
<p>AXI就是AHB的高速强化版，专用于CPU和缓存、内存的通信；Lite则是介于AXI与AHB速度之间的“青春版”，可以用于CPU控制较远的寄存器，或在小IP中使用以减小面积；Stream就是一个没有寻址功能的“管道”，数据管子进管子出，因为没法寻址所以也只能一对一传输</p>
</blockquote>
<p>注意：<strong>AXI可以“向下”兼容AHB和APB接口</strong></p>
<h3 id="AXI综述"><a href="#AXI综述" class="headerlink" title="AXI综述"></a>AXI综述</h3><p>在硬件层次，AXI4允许每个AXI主从对使用不同的时钟。 此外，AXI协议允许插入寄存器片（通常称为流水线级）以帮助实现时序收敛</p>
<p>AXI总线共有5个单方向通道，分别是</p>
<ul>
<li>读地址通道（read address channel），用<strong>AR</strong>标记</li>
<li>写地址通道（write address channel ），用<strong>AW</strong>标记</li>
<li>读数据通道（read data address channel），用<strong>R</strong>标记</li>
<li>写数据通道（write data channel ），用<strong>W</strong>标记</li>
<li>写响应通道（write response channel ）用<strong>B</strong>标记</li>
</ul>
<p>每一个通道都包含了一组信号线，这些线的作用不同，位宽大都可以自定义，但是每个通道都会包含两根<strong>握手信号线</strong>：READY和VALID。握手机制是AXI总线中主机和从机之间建立传输的一个标志。VALID信号来自于源设备（source），READY来自于目标设备（destination），所有的信息源设备都会发送一个VALID信号，去展示出自己通道内此时的东西是否是有效的。</p>
<p>传输建立之前，目标设备都会发送一个READY信号，去展示自己是否准备好，当VALID和READY都是高电平的时候，对应的通道就被“使能”，传输也就建立了</p>
<p>所以说<strong>通道握手</strong>就是源设备发送VALID，目标设备发送READY</p>
<p>每个通道都有不同的功能：</p>
<p><em>读地址通道AR</em>和<em>写地址通道AW</em>用于在本次传输中收发所需的地址和控制信息</p>
<p><em>读数据通道R</em>携带主机要读出的数据</p>
<blockquote>
<p>对于读过程来说，从设备是源设备，主设备是目标设备，所以在R通道内部，VALID是从设备发出，READY是主设备发出</p>
</blockquote>
<p><em>写数据通道W</em>把主设备要写入从设备的数据转发给从设备</p>
<p><em>写响应通道B</em>用于提交写处理的响应，需要注意：AXI协议规定所有写处理都需要返回响应信号</p>
<p>下图展示了AXI4读事务中读地址通道读数据通道的工作状态</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220117132601780.png" alt="image-20220117132601780"></p>
<p>在Xilinx Vivado中，给出了一套AXI总线的实现，如下所示</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206175043205.png" alt="image-20220206175043205"></p>
<p>看起来很复杂，但实际上上面大多数接口都可以合并为主机AXI通道接口（AXI4_MASTER_M_AXI）和从机AXI通道接口（AXI4_SLAVE_S_AXI），同时还具有两个全局的接口：复位端ARESETN和时钟端ACLK，也就是如下图所示，两边带加号的两套接口就是主机和从机的AXI通道接口，带ACLK、ARESET的信号分别是全局（INTERCONNECT开头）、主机（M00开头）、从机（M00开头）的时钟和复位信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206175138145.png" alt="image-20220206175138145"></p>
<h3 id="总线信号"><a href="#总线信号" class="headerlink" title="总线信号"></a>总线信号</h3><p>这部分简单介绍信号的内容，具体什么信号负责什么工作会在后面的数据读写部分介绍</p>
<p><strong>全局信号</strong></p>
<ul>
<li><p><strong>ACLK</strong>：总线时钟</p>
<p>  这是一个单bit信号，系统会根据总线时钟在<strong>上升沿触发</strong></p>
<blockquote>
<p>一个常见的问题，自行设计的AXI总线有时候会在主设备输入和从设备输出端有意或无意地接入组合逻辑电路，这样容易导致时序混乱。比较常用避免这一情况的方法是在输入输出AXI时钟接口的信号线上接入reg型变量，引入时序要素</p>
</blockquote>
</li>
<li><p><strong>ARESETn</strong>：总线全局复位，低电平触发，支持异步复位，但是要让这个复位信号触发，还是同步于时钟，这就是所谓的<code>异步复位同步触发</code></p>
<p>  需要注意：协议要求复位高于一切，也就是说在复位期间，ARVALID和AWVALID同时还有WVALID需要全部置低，不允许有用信号产生</p>
</li>
</ul>
<p>上面的两个总线要求看着很复杂，实际上代码实现就是</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> n_rst) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span>(！rst_n_0) <span class="keyword">begin</span></span><br><span class="line">        RVALID&lt;=<span class="number">1&#x27;b0</span>;</span><br><span class="line">        BVALID&lt;=<span class="number">1&#x27;b0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> </span><br></pre></td></tr></table></figure>

<p>无论是主机和从机都应该加上这段复位代码</p>
<p><strong>写地址</strong>通道AW总线信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182406726.png" alt="image-20220206182406726"></p>
<p><strong>写数据</strong>通道W总线信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182721487.png" alt="image-20220206182721487"></p>
<p>写数据通道支持8、16、32、64、128、256、512、1024位宽，每8位有一个字节通道写选通控制信号WSTRB，用于表示数据总线上有效的字节</p>
<p><strong>写响应</strong>通道B总线信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182838501.png" alt="image-20220206182838501"></p>
<p>写响应通道提供了用于从设备完成写入响应的方法，每个响应都对应于一次猝发传输或普通<strong>传输的完成</strong>，而不是对应于每个传输的数据</p>
<p>BRESP返回值的二进制表示如下</p>
<table>
<thead>
<tr>
<th>BRESP[1:0]值</th>
<th>响应含义</th>
</tr>
</thead>
<tbody><tr>
<td>00</td>
<td>OKAY，写入成功</td>
</tr>
<tr>
<td>01</td>
<td>EXOKAY，独占式存取成功</td>
</tr>
<tr>
<td>10</td>
<td>SLVERR，从机已经和主机建立了连接并接收到数据，但出现错误</td>
</tr>
<tr>
<td>11</td>
<td>DECERR，解码错误，互联模块无法正确译码并连接到从机</td>
</tr>
</tbody></table>
<p><strong>读地址</strong>通道AR总线信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182540541.png" alt="image-20220206182540541"></p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182553867.png" alt="image-20220206182553867"></p>
<p>读地址通道和写地址通道机制相似，因此<strong>具有类似的总线信号</strong>，含义都一样</p>
<p><strong>读数据</strong>通道R总线信号</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206182430607.png" alt="image-20220206182430607"></p>
<p>支持8、16、32、64、128、256、512、1024位宽，使用读响应RRESP表示读操作完成的状态</p>
<h3 id="握手信号"><a href="#握手信号" class="headerlink" title="握手信号"></a>握手信号</h3><p>对于五个通道而言，它们都使用<strong>各自的</strong>READY和VALID实现握手机制去控制五个通道内部的处理，包括传递地址、数据及控制信息。这个两路双向控制的机制让主设备和从设备都能够控制通道内部的信息交换速率。</p>
<p>源设备能够产生valid信号告知目标设备通道内部信息是否有效；目标设备能够产生ready信号告知源设备是否准备好了接收信息。如果要完成一次传输（一拍）则需要两个信号都是高电平。</p>
<p>和时钟、复位信号类似，ready和valid信号之间不能有组合逻辑链接——就是两个信号其实相互无关，只是他们共同决定传输是否开始，即valid产生是因为信号有用而产生，而不是有ready信号出现才产生；类似地，ready信号是因为目标设备做好了准备才产生，并不是valid有效而产生），这也就是所谓的<strong>独立握手</strong></p>
<p>为了避免死锁，握手信号还存在一定依赖关系，最基本的两条依赖就是：</p>
<ul>
<li>valid信号不依赖于交易中其他元件的ready信号</li>
<li>ready信号能够等待确认valid信号</li>
</ul>
<p>需要注意：<strong>依赖关系是指握手建立的条件，而不是信号产生的条件</strong></p>
<p>读写传输中分别要满足以下依赖关系：</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206133534813.png" alt="image-20220206133534813"></p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206133544644.png" alt="image-20220206133544644"></p>
<p>协议中给出了几个典型情况下对于握手信号的要求：</p>
<p><strong>如果valid信号先于reday，这个情况必须要主机保持有效信号直到从机准备完毕</strong></p>
<p>下图给出了这种情况下的时序图</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220117180138901.png" alt="image-20220117180138901"></p>
<p>源设备在T1时刻之后产生了有用的信息，于是拉高VALID信号，T2时刻时钟上升沿处采样，系统<strong>才</strong>知道信息有效；而目标设备在T2时刻之后才准备好，同时发送ready信号，错过了T2时刻上升沿，所以源设备必须保持它携带的的信息稳定知道T3时刻，此时valid、ready握手信号都为高电平，于是在T3时刻上升沿传输发起</p>
<p><strong>如果ready先于valid，这个情况必须要让从机等待主机发出有效信号</strong></p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220117180536584.png" alt="image-20220117180536584"></p>
<p>T1时刻之后从机准备好，READY信号开始拉高，到了T2时刻的上升沿，系统知道目标设备准备好了；但是主设备在T2之后才生成有效数据并将VALID信号拉高，所以真正有效的传输要等到T3时刻</p>
<p><strong>如果ready和valid同时到来，这个情况必须要等待到下一个时钟上升沿</strong></p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220117185812744.png" alt="image-20220117185812744"></p>
<p>这个很容易理解，时钟信号上升沿采样，双方都没有拿到valid、ready，自然要同时保持直到下个上升沿</p>
<p>总的来说就是<strong>源设备的VALID信号只要没准备好就可以拉低，READY拉高拉低标准取决于目标设备，和VALID无关</strong>，所以这也印证之前讲的VALID和READY之间不能有组合逻辑。</p>
<blockquote>
<p>协议标准中不建议随时把READY拉低，因为在READY先到的情况下需要使用一个上升沿确定READY拉高，然后必然又要花费一个上升沿等待VALID，这样完成握手其实已经等待了两个时钟周期</p>
</blockquote>
<p>总结一下，AXI总线的握手规则是为了<strong>有效传输</strong>而设立的，从机和主机的通讯需要建立在有效信号VALID和准备信号READY都拉高的基础上，如果主机向从机提出读写请求，就相当于主机先准备好，然后等待从机发出有效数据；如果从机向主机提出读写请求，就相当于从机先准备好，然后等待主机发出有效数据——<strong>这些信息都是通过握手通道实现数据交换的</strong></p>
<h3 id="AXI猝发传输"><a href="#AXI猝发传输" class="headerlink" title="AXI猝发传输"></a>AXI猝发传输</h3><p>AXI4协议规定了3种猝发传输，<strong>一次猝发只能传递4KB的数据</strong>，根据数据总线宽度变化，决定有多少<strong>拍</strong>（transfer）</p>
<blockquote>
<p>这个数据量是根据总线宽度决定的</p>
<p>假设我们有32位数据线，则每一拍实际传输4个字节数据，这时候一共需要128拍才能传完4KB的数据，所以我们把128叫做<strong>猝发传输长度</strong>，也就是发起了多少次传输/拍（transfer）。猝发传输长度是根据总线宽度和这个上限4KB共同决定的——当然也可以不传满</p>
</blockquote>
<ul>
<li>固定猝发</li>
<li>递增猝发</li>
<li>回卷猝发</li>
</ul>
<p>猝发传输类型由ARBURST和AWBURST信号选择，如下所示</p>
<table>
<thead>
<tr>
<th>ARBURST,AWBURST</th>
<th>猝发类型</th>
<th>描述</th>
<th>访问</th>
</tr>
</thead>
<tbody><tr>
<td>00</td>
<td>固定</td>
<td>对固定地址进行猝发访问，按顺序进行数据压栈/入队</td>
<td>FIFO类型</td>
</tr>
<tr>
<td>01</td>
<td>递增</td>
<td>地址递增地进行猝发访问，一次完成一个序列的传输</td>
<td>普通顺序寄存器</td>
</tr>
<tr>
<td>10</td>
<td>回卷</td>
<td>地址递增地进行猝发访问，但在边界时返回低地址</td>
<td>高速缓存行</td>
</tr>
<tr>
<td>11</td>
<td>保留</td>
<td>N/A</td>
<td>N/A</td>
</tr>
</tbody></table>
<p><strong>固定猝发传输</strong>是指每一次传输都是重复的往同一个地址写东西，数据会按顺序“塞进”对应地址</p>
<p><strong>递增猝发传输</strong>是指每一次传输都在上一次传输地址的基础上增长，地址增长多少取决于猝发传输容量（burst size）</p>
<blockquote>
<p>假设每一次传输的burst size都是32位（4个字节），下一次的传输地址会增加4，地址一点点增长，数据也对应写入</p>
<p>这种方式常用于一般的存储单元顺序访问，比如ram读写</p>
</blockquote>
<p><strong>回卷猝发传输</strong>（也称为回环猝发传输）是在递增猝发传输的基础上，当写到最高地址的时候又回到最开始的最低起始地址</p>
<blockquote>
<p>这种方式常常用于处理高速缓存的访存</p>
</blockquote>
<p>比较特殊的是<strong>回卷猝发</strong>，<strong>要求起始地址必须对齐传输大小且促发长度只能是2、4、8或16</strong>，更大的猝发传输只支持递增类型，<strong>回卷和固定类型只限于小于16拍的猝发传输</strong></p>
<blockquote>
<p>递增传输支持1到256拍的传输；其他猝发传输只能支持1到16拍，这样为了保证数据总量不超过4KB</p>
</blockquote>
<p>需要再次强调：猝发传输容量（burst size）实际上是数据总线位宽，猝发传输长度（burst length）是拍数，两个的乘积就是数据的总量，不能超过4KB</p>
<h3 id="数据读写"><a href="#数据读写" class="headerlink" title="数据读写"></a>数据读写</h3><p>之前已经说过，AXI4总线包含五个基本通道，分别处理地址读/写（AR、AW）、数据读/写（R、W）和写响应（B）</p>
<p>在写事务过程中，AXI总线将采取如下图所示的方式</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206173407882.png" alt="image-20220206173407882"></p>
<p>需要使用到W、AW、B三个通道</p>
<p>而参考之前介绍过的读事务示意图，读操作中只需要使用R、AR两个通道，不难发现<strong>AXI通道可以实现同时读写</strong></p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220117132601780.png" alt="image-20220117132601780"></p>
<p>在读数据过程中，主设备发出请求后首先进行主从设备仲裁，仲裁器通过请求后，主设备才能和从设备建立连接，然后主设备通过AR通道将要读取的数据地址发送给从机（预先要进行握手），主机进入等待状态，从机根据指令将数据通过R通道返回主机，在传输过程中如果使用了猝发传输，那么burst size猝发传输容量就是上图所示每次传输的数据大小，transfer拍就是上图中传输的次数，二者乘积要保证不大于4KB，传输过程中要保证开始传输的时候进行握手，后续传输中握手信号保持有效状态（RVALID=1，RREADY=1），<strong>在结束读取之前的最后一个数据包发出后（最后一次传输结束前），从设备要发出一个结束信号，将RLAST信号拉高一个周期表示传输结束</strong></p>
<p>在写数据事务中，需要主设备通过AW通道向从设备发起写入请求并传输写入的地址，猝发类型也会一并在这个阶段通过AW通道传输给从设备，随后从设备会等待主设备的写入数据，主设备握手完成后就会通过W通道向从设备写入数据。等待所有数据写入完成后，从设备会通过B通道向主设备发送写响应，标志数据的写入状态。需要注意，<strong>最后一个数据包写入后（最后一次传输结束前），主设备需要拉高WLAST信号来表示传输结束</strong></p>
<blockquote>
<p>强调一下WSTRB表示写选通控制信号</p>
</blockquote>
<p>只有WDATA中数据有效（即WVALID高电平）时，才能发起写传输并写入有效数据；如果WVALID为低电平（数据无效），则这个时候WSTRB可以为任意值，但是协议中建议：若WVALID为低电平，WSTRB最好维持上次的值或是统一变为低电平以维护代码逻辑、增加系统稳定性、节省动态功耗</p>
<p>在整个传输过程中，主设备往往会向从设备确认<strong>ID</strong>，也就是通过AWID、BID、ARID、RID这四个4位的信号进行ID匹配，要求：</p>
<ul>
<li><strong>从设备在响应通道中返回的BID必须匹配主设备在写入过程中发送给从设备的AWID</strong></li>
<li><strong>从设备在读数据通道中返回的RID必须匹配主设备发送读取地址时一并发送给从设备的ARID</strong></li>
</ul>
<p><em>这个要求是AXI标准协议独有的，在AXI-Lite总线中不需要确认ID，这就是为什么AXI标准主机不能兼容AXI-Lite从机；但AXI-Lite主机可以兼容AXI标准从机</em></p>
<h3 id="总线互联-1"><a href="#总线互联-1" class="headerlink" title="总线互联"></a>总线互联</h3><p>AXI总线支持以下几种形式的总线互联结构，可以组织成AXI总线矩阵</p>
<ol>
<li><p>直通模式</p>
<p>单主单从设备互联，AXI不执行任何转换或流水线功能，无总线延迟，不消耗逻辑资源</p>
</li>
<li><p>只转换模式</p>
<p>单主单从设备互联，AXI执行不同的转换或流水线功能，主要包括</p>
<p>数据宽度转换：将宽数据转换为窄数据</p>
<p>时钟速率转化：跨高速/低速设备传输数据</p>
<p>总线标准转换：标准AXI转AXI-Lite、AXI4转AXI3等</p>
<p>流水线传输：对寄存器或FIFO执行访问</p>
<p>该模式下AXI互联不包含仲裁、解码或布线逻辑，但可能产生延迟</p>
</li>
<li><p>N-1互联模式</p>
<p>多主一从设备互联</p>
<p>这个配置中需要使用一个仲裁逻辑，但是并不需要地址译码逻辑</p>
<p>当然，它也可以执行数据宽度和时钟速率转换</p>
</li>
<li><p>1-N互联模式</p>
<p>一主多从设备互联</p>
<p>常见于处理器和片上内存/Flash连接，这需要一个存储器映射的从外设，AXI总线不执行仲裁，但是需要一个解码逻辑</p>
</li>
<li><p>N-M互联模式</p>
<p>多主多从连接</p>
<p>这种模式下，AXI提供<strong>共享地址多数据流（SAMD）拓扑结构</strong>和<strong>稀疏互联开关拓扑结构</strong></p>
<p>共享读写地址仲裁结构中将读写指令交由两个仲裁器进行分配；稀疏互联开关拓扑结构则使用两套独立的多路选择器-译码器电路控制指令</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206140857642.png" alt="image-20220206140857642"></p>
</li>
</ol>
<h3 id="AXI4-Lite"><a href="#AXI4-Lite" class="headerlink" title="AXI4-Lite"></a>AXI4-Lite</h3><p>AXI4-Lite简称AXI-Lite，是AXI4接口的子集，专用于片上寄存器通信，它的规模较小，因此设计和验证要求也更少，相对于AXI4标准协议，它的特点有：</p>
<ul>
<li>所有传输的猝发长度（burst length）为1，也就是说<strong>AXI-Lite不支持猝发传输</strong></li>
<li>所有访问数据宽读和数据总线宽度相同</li>
<li>支持32位或64位数据总线宽读</li>
<li>不支持互斥性操作</li>
</ul>
<p>AXI-Lite接口信号线相对较少，如下所示</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206141519091.png" alt="image-20220206141519091"></p>
<p><strong>AXI-Lite作为主设备接口，可以直接兼容AXI标准从设备；但是AXI标准主设备大多需要经过AXI2AXI-Lite转接才能兼容AXI-Lite从设备，因为AXI主设备会要求从设备返回AXI ID，但AXI-Lite不需要</strong></p>
<p>可以直接理解成AXI标准主设备=AXI-Lite主设备，但AXI-Lite从设备&lt;AXI标准从设备，这也符合AXI-Lite减小从设备规模占用的设计目的</p>
<h3 id="AXI-Stream"><a href="#AXI-Stream" class="headerlink" title="AXI-Stream"></a>AXI-Stream</h3><p>AXI-Stream用于<strong>连接直接交换数据的片上器件</strong>，接口将产生数据的设备视为主设备，将接收数据的设备视为从设备，在二者之间建立<strong>数据流通道</strong>（有点类似于Linux里面的管道传输概念，主设备的输出数据会直接输入从设备）。AXI-Stream<strong>不支持内存映射</strong>！</p>
<p>AXI-Stream可以允许无限制的突发传输，直观来说就是AXI-Stream主机可以一直向从机写数据</p>
<p>不过<strong>AXI-Stream也可以支持多主一从的连接</strong>，允许建立互联结构，这样该结构可以执行扩展、压缩和路由操作</p>
<p>正如它的名字所说，AXI-Stream常用于各种基于数据流结构的片上外设</p>
<p>它的信号表如下所示：</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206142310001.png" alt="image-20220206142310001"></p>
<p>ACLK、ARESETn大家都熟悉，不再多介绍。TVALID和TREADY信号是AXI-Stream的专用握手信号。主设备不允许在确认TVALID前确认TREADY，一旦取人TVALID就必须一直保持该状态直到握手完毕；从设备允许在确认TREADY前等待确认TVALID，不过在TVALID信号确认前从设备可以释放TREADY</p>
<p>这个握手原则是为了<strong>保证从设备只需要快速输出数据而主设备应该及时接收</strong></p>
<p>AXI-Stream的结构和AXI标准协议中的写数据通道很类似——事实上Stream就是把AXI标准协议中的W通道拿出来，这也就是为什么它不支持内存映射。</p>
<h3 id="AXI总线IP核使用"><a href="#AXI总线IP核使用" class="headerlink" title="AXI总线IP核使用"></a>AXI总线IP核使用</h3><p>整套AXI的IP主要包含三部分</p>
<ul>
<li>主机</li>
<li>从机</li>
<li>AXI连接器</li>
</ul>
<p>主机IP实现了AXI主机与主设备寄存器或控制器的连接，从机IP实现了AXI从机与从设备寄存器的连接，二者都依附主设备或从设备存在；而AXI连接器则表现得像一个独立的模块，一个标准的AXI连接（直通模式）如下所示</p>
<p><img src="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/image-20220206172823626.png" alt="image-20220206172823626"></p>
<p>事实上AXI连接器这个IP还可以进一步拆分，用不同分工的子IP实现各种需要AXI总线完成的功能，在Xilinx的FPGA设备中提供了如下几类IP：</p>
<ul>
<li><strong>AXI Register Slice</strong>：用于流水线操作的AXI总线上缓存（寄存器），常用于处理关键时序路径</li>
<li><strong>AXI Data FIFO</strong>：带FIFO的AXI总线，可用于跨时钟域或数据流缓存</li>
<li><strong>AXI Interconnect IP/AXI SmartConnect IP</strong>：用于内存映射地连接片上外设，SmartConnect IP相对于Interconnect IP提供更高带宽和更低延迟，但是占用更多片上资源</li>
<li><strong>AXI Direct Memory Access（DMA） engine</strong>：带内存映射的DMA通道，可用于实现AXI-Stream到AXI标准协议的转换</li>
</ul>
<p>除此之外还有一系列具有辅助功能的AXI IP设备，部分设备已经被集成到了AXI Interconnect IP/AXI SmartConnect IP中</p>
<ul>
<li><strong>AXI Performance Monitors and Protocol Checkers</strong>：用于调试和分析片上外设问题的特殊AXI连接器</li>
<li><strong>AXI Verification IP</strong>：用于仿真验证和性能分析</li>
<li>AXI Crossbar：连接多个相似主机和多个相似从机（低配版总线矩阵）</li>
<li>AXI Data Width Converter：AXI总线宽度（也就是之前说的总线大小axi-bus-size）转换</li>
<li>AXI Clock Convertor：可以跨时钟域连接主从的AXI总线</li>
<li>AXI Protocol Convertor：将AXI4标准协议、AXI-Lite、AXI3主机和另一个不同AXI协议从机相连的AXI协议转换器</li>
<li>AXI MMU：为AXI Interconnect IP提供地址解码功能</li>
</ul>
<p>Vivado还支持封装带有AXI从机接口的IP核，从而实现基于AXI的片上系统</p>
<h3 id="其他资料"><a href="#其他资料" class="headerlink" title="其他资料"></a>其他资料</h3><p>上述资料根据Xilinx的Vivado AMBA总线使用手册和ARM AMBA协议原文整理编辑，同时参考了<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1gy4y1Y7zr">视频讲解</a>和其他网络资料。如果有兴趣的读者可以自行翻阅Github搜索AXI总线的实现，这里不再介绍</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">FPGA</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/02/06/FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E3%80%90AMBA%E6%80%BB%E7%BA%BF%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-ESP32-IDF学习9【HTTP客户端】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/24/ESP32-IDF%E5%AD%A6%E4%B9%A09%E3%80%90HTTP%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%91/">ESP32-IDF学习9【HTTP客户端】</a>
    </h1>
  

        
        <!-- 不蒜子统计 -->
<span id="busuanzi_container_page_pv" style='display:none' class="archive-article-date">
	<i class="icon-smile icon"></i> 本文阅读数:<span id="busuanzi_value_page_pv"></span>次</span>

<a href="/2022/01/24/ESP32-IDF%E5%AD%A6%E4%B9%A09%E3%80%90HTTP%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%91/" class="archive-article-date">
  	<time datetime="2022-01-23T17:55:43.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2022-01-24</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本博文会简要介绍ESP-IDF下实现HTTP客户端的方法</p>
<h2 id="TCP协议栈"><a href="#TCP协议栈" class="headerlink" title="TCP协议栈"></a>TCP协议栈</h2><p>ESP使用lwIP作为嵌入式的TCP/IP协议栈支持</p>
<p>lwIP是一套在MCU层级上用C实现的IP协议栈，可以运行在裸机/RTOS/嵌入式Linux，乐鑫为ESP32提供了相关移植包</p>
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">ESP32</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2022/01/24/ESP32-IDF%E5%AD%A6%E4%B9%A09%E3%80%90HTTP%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2022 RedlightASl
			本站文章全部使用CC-BY-SA与GPL3.0协议开源
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
		<!-- 不蒜子统计 -->
		<span id="busuanzi_container_site_pv">
			本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
		<span class="post-meta-divider">|Σ(OvO)|</span>
		<span id="busuanzi_container_site_uv" style='display:none'>
			本站访客数<span id="busuanzi_value_site_uv"></span>人</span>
    </div>
  </div>
</footer>

    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">杂项</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习与机器视觉</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">电路设计</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">测试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">电赛笔记</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">stm32</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">C语言进阶</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">ESP32</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">IoT</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">嵌入式Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">FPGA</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">IC</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">RISCV</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">一生一芯</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://dawncraft.cc/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>软院全栈dalao</a>
            </li>
          
            <li class="search-li">
              <a href="http://sianiumiao.xyz/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>中科院做电源的佬</a>
            </li>
          
            <li class="search-li">
              <a href="https://redlightasl.github.io/about/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>广告位招租</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">这个天天摸鱼的微电人，&lt;br/&gt;  二刺螈（迫真），&lt;br/&gt;  因为学不懂编程改行硬件的菜b，&lt;br/&gt;  是谁呢？&lt;br/&gt;  没错就是我(即答)</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>